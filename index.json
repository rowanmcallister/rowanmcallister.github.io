[{"authors":["admin"],"categories":null,"content":"I am a machine learning manager at the Toyota Research Institute in California focusing on autonomous vehicle planning. Previously, I was a PhD student at the Machine Learning Group with Carl Rasmussen and a postdoc in the Robotic AI and Learning Lab with Sergey Levine, working on probabilistic modeling toward data-efficient reinforcement learning and autonomous vehicle planning.\n","date":1661817600,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1661817600,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://rowanmcallister.github.io/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"I am a machine learning manager at the Toyota Research Institute in California focusing on autonomous vehicle planning. Previously, I was a PhD student at the Machine Learning Group with Carl Rasmussen and a postdoc in the Robotic AI and Learning Lab with Sergey Levine, working on probabilistic modeling toward data-efficient reinforcement learning and autonomous vehicle planning.","tags":null,"title":"Rowan McAllister","type":"authors"},{"authors":["Rowan McAllister"],"categories":[],"content":" If you’re anything like I was after academia, wondering how to navigate tech’s job market, then this post is for you. The lessons here are intended to help inform you what you can do before—and during—your job search to increase your chances of getting offers and improving those offers. With special thanks to Gregory Kahn, Kate Rakelly, Boris Ivanovic, Rebekah Baratho, Ashwin Balakrishna, Jessica Yin, Nick Rhinehart, Jessica Cataneo, Rares Ambrus, for their input and feedback. Also thanks to Roberto Calandra who guided me through my own job search. Opinions below are not necessarily shared by all who helped.\nWhy? Why would you want to leave academia for industry? There’s different kinds of industry positions that may appeal to you. From being embedded in a production team writing production code (typical of “research engineer” or “software engineer” roles), to a startup, to basically being an academic paid an industry salary to publish papers as a “research scientist”. Benefits of industry include:\n More pay: Often 5x more. Such a large increase can give you more options in life. More support: It is inefficient for companies to pay top dollar for your skill in X while having you be distracted by Y. So mid–large size companies usually have more administrative support than universities can afford to help you work more effectively. This means easier and faster reimbursement processes, for example. Visa issues? Now you have lawyers on call to help you. Companies are better incentivized to remove your blockers and distractions that impede your work. This includes financial blockers too. As a researcher in industry, you will generally have more funding for your research projects too, and internal applications for that funding is simpler. Can be interesting: If working on a product, you might be able to see the fruits of your labor sooner, which can feel rewarding. Can still do research: While you might not have as much “academic freedom” compared to university positions, the “freedom gap” between industry and companies has been closing in recent years. Today, many industrial research groups offer significant academic freedoms to attract talent, especially for research scientist positions when hired as an “individual contributor” (IC): it’s often up to you to figure out your research agenda within fairly broad bounds. In research, your manager isn’t necessarily a “technical manager” like a PhD supervisor—who has more sway on your research direction—but more often a “people manager” that exists to help you be more effective, remove roadblocks, and help build connections for you to apply your work internally. Can still return to academia later: The academic door won’t close. It is easier nowadays to switch back and forth between academia and industry.  I remember ominous warnings at grad school to be careful: those who venture from academia into industry rarely return! Once someone gets used to higher pay and standards of living, they cannot bring themselves to return! Scary stuff. While it’s true many people don’t later return, there’s many additional reasons beyond pay for this: (1) a selection bias of those who wanted to leave academia anyway, (2) size(industry) \u0026gt; size(academia), (3) better work-life balance, vision, product, and purpose. You can always return to academia later if you like, but sometimes the grass really is greener: you may find you’re happier in engineering or industrial research roles. That said, if you do want to hold the academic door open after you leave, try to continue publishing while in industry, to stay relevant, avoiding a big publication gap in your resume. Another option is to do academia and industry concurrently. Those majority-academia, like professors, might supplement their salary by (1) spending 20% of their time at a company, or (2) consulting for multiple companies a few hours each month, or (3) have a startup on the side. Even industry folk can sometimes find lecturer positions to teach a class per year.    While in Academia Network Networking is about building relationships with key people in the industry you wish to enter. Application success is a function of both what you know and who you know. “Who you know” isn’t necessarily about nepotism, there’s many legitimate benefits including familiarity, pre-vetting, and simple awareness of you. When key people are aware of any skills of yours useful to them, they can then help:\n inform you of the available positions, increase the probability of you getting an offer, improve your offer (increasing your compensation), and create new positions for you to apply to (that weren’t on their website beforehand).  Networking is also about building up a set of colleagues and mentors that you trust, who would like to see you succeed in your career. Key people are useful for getting in certain doors, but colleagues and mentors can help show you which doors exist in the first place, and give you insight about what\u0026rsquo;s beyond each. Many hyped-up companies have non-obvious downsides you’ll be unaware of, and there are many modest companies you haven’t heard of which are relevant to you, which a supportive network can help you identify. They can also give you a warm introduction to employees within different companies, which themselves could be your internal champion or simply be happy to have an informal chat about their company before you decide to formally apply or not. Mentor relationships—those with someone more advanced in their career than you—are more common in older fields like law or medicine, but there’s no reason you can’t seek out mentors in tech too: people generally enjoy helping through giving advice, and may appreciate someone values their career advice or wants to follow a similar path as they did, or simply the thrill of vicariously living through all the early-stage career decisions and strategizing again.\nStart early. Networking takes time, the more time you have the better, so start early, ideally years before your graduation, so you can build up contacts at each company before you apply, and build an understanding of their wider organizational structure, and where you might like to fit in later. Feeling like an “insider” to a company rather than an “outsider” can be a big confidence booster during the application and subsequent interview process.\nConferences and workshops: You can network at conferences e.g., job booths and corporate mixers. Networking is typically more effective at smaller, more focused conferences like CoRL which has several hundred physical attendees. This number is small enough that you will re-bump into people again and again during the week, compared to larger conferences like NeurIPS and CVPR with thousands of physical attendees, where there are just too many people: you’ll chat to someone once and never see them again. At larger conferences you may find it easier to network at specific workshops within the conference, being a more manageable size to get to know people. Workshops also have more of a \u0026ldquo;many-to-many\u0026rdquo; format, vs main conference where it\u0026rsquo;s \u0026ldquo;many-to-one\u0026rdquo; (aka many people trying to mob one poster).\nUnique skills: Networking pays off big time if you can (1) discover which companies need your skill X, and (2) make that company aware that you have skill X. During your time in academia you probably developed some unique skills, knowledge, or insights. Depending on how much a company wants X, they can move mountains to convince you to join them: break their own hiring process, overrule their internal compensation limits, create custom positions just for you. While uncommon, it happens, because ultimately “processes” and “policies” are just words, the truth is that companies are competing for talent and everything is negotiable, it all depends how much companies value X. So find out!\nOrganize workshops: Workshops are a great way to network. If you know what area you want to work in after graduation, consider organizing a workshop on this topic. As an organizer, you’ll meet speakers and authors on friendly terms, having just provided them an additional opportunity to showcase their work. In addition, you’ll get to work closely with organizers from various labs and companies in this area. Inviting speakers or panelists from companies you are interested in can also be a great way to learn more about the research interests and projects going on in companies you may want to apply to in the near future.\nVisit other labs: besides internships, you can also visit others labs. This is a good way to keep your learning curve steep, meet many new students and professors, learn their philosophies and methods in more depth (especially since most tech knowledge is “dark knowledge”: insights and intuitions not explicitly written down anywhere). Visiting is a great way to get outside your own lab’s echo chamber, while additionally bringing your lab’s strengths and philosophies to new labs, which the new lab can benefit from, and can create really interesting cross-collaborations. Cross collaborations are much easier when you’re physically together, grabbing coffee and lunch together too. I initially learned a lot from my own lab, but after I understood better how everyone thought and had then already benefited from understanding their intuitions, it was then more fruitful to branch out to work with visiting scholars from other universities, or folks from neighboring labs within the same university.\nSpeak to industry: In academia, you are free to blab about what you work on, including technical details. Industry is not like this, NDA agreements often restrict what you can communicate externally. So, while you are in academia, exploit your temporary freedom to communicate your research to key people. Offer to give talks at companies starting 1–2 years before graduation. Many companies have internal reading groups and will appreciate an external speaker for a change! It’s not as weird as it might sound to invite yourself to speak, rather, I suspect it’s an underutilized strategy to network with key people. You meet people inside each company early on, and have a chance to reinforce those relationships at conferences etc, creating internal champions there when you later apply for positions. It’s also a chance to learn about the company’s priorities, interests, technical strengths and weaknesses before you apply: by listening to the questions they ask at your talk, or what they most enjoyed, or at more relaxed conversations over lunch. This informs you of the skills they’ll likely be looking for when you later apply, what you could research in the meantime, and can then highlight your solutions to their problems in your CV or tech talk. It’s much easier to get hired when (1) people like you and (2) you clearly bring skills they need. Speaking at companies can be a fun half-day trip including lunch together too. I used to think “what do I know, these secretive, well-funded companies are probably way ahead of what our small underfunded university lab is doing”, but I was wrong. Companies are usually behind the SOTA given their product focus and risk aversion, so they often are interested in hearing what cutting edge research that you have been up to!\nOnline Presence In 2022 academia, it’s important to have an online presence. Use this to advertise your work online. Communication is a critical role for any scientist, so take the time to make a professional website, nice videos, tweets, linkedin posts, publication links on your website without paywalls. It’s important, since posting your material online scales better than manual networking. By crafting engaging material about your research, e.g., videos, you increase its reach and can have more impact: a lot more people will watch your video than read your paper. Simple awareness of your work is now half the battle in overhyped fields like machine learning where there is now a tough competition for attention.\nOpen source code: Open sourcing code that actually gets used (aka stars on github) is a great sign when people evaluate you. So if you want others to read, use, and cite your work, you have to make it as easy as possible. This doesn’t only mean open-sourcing the code, but open-sourcing clean, executable code with a full README, notebooks, reproducible environments (e.g., requirements.txt) that allow researchers to instantly pick up from your results with ease. Think of all the frustrations you may have had when trying to use another researcher\u0026rsquo;s code, and what made it frustrating for you. After watching a great video, people might want to try your method out themselves, and having easily-accessible, clean code makes that possible.\nInternships Internships are a good way to build connections and “test the waters”. While undergrad interns have less freedom in what the internship will entail, typically being told what to work on when you arrive, PhD interns have more control of what the contents of the internship will be.\nDo internships, to build connections and build a sense of what life is like beyond academia. Beyond improving your CV, internships are a great source of information on what a particular company or sector is like. Internships can also reveal what you want in your career (this can be hard to know when you don’t know what your options are yet). Internships can teach you what to target when applying for full-time jobs later, what work you enjoy, and perhaps more importantly: what you don’t like. Meaning, it’s better to “lose” 3 months doing the “wrong” internship than 3 years in the “wrong” job. So treat internships as an opportunity to learn about yourself, to “test” different types of jobs. And while there’s a natural tendency to intern at familiar places that you (or your supervisor) already have connections at, consider that you might learn more interning at unfamiliar places, and could be pleasantly surprised. It’s only 3 months, so internships might be better spent reducing the “unknown unknowns” in your life than reinforcing what you already knew about yourself.\nExamples: For my own experiences, an internship at an airport during undergrad taught me that I did not want to be an aeronautical engineer. Learning this was valuable: I switched majors into robotics before graduating, saving my career 2-3 years on the wrong path had I switched after graduating. During my masters I interned with Google, which was great, but I learned that I didn’t want to build a generic skill set which a million other programmers knew too. Rather, I learned that I wanted to be an expert in something: to develop and possess specialized skills, which prompted the PhD. During my PhD I had a great internship with UberATG, where I developed an interest in autonomous vehicles which ultimately led to my current position.\nDo internships while you can: Internships are a bit magical. At no other time after your degree can you repeatedly walk into various companies for only 3–4 months, do cool work, and walk out with everyone happy, and it actually looks good on your CV too! Changing companies every three months after graduation would create red flags, but oh if it was an “internship”, well that looks good! Internships are typically before graduation, though some companies now offer internships immediately after graduation too. And to ensure you can intern, plan early, and coordinate with your advisor. Some PhD advisers are OK with internships, and some are not. Common reasons for being against internships are if they aren\u0026rsquo;t research related, delay graduation, etc. So figuring out where your adviser stands as early as possible is good, and also coming up with a game plan early. Caveat: Internships do carry some cost. Besides adviser resistance, they can impede your research momentum and delay graduation. Opposed to your job search strategy where more applications is generally better, internship applications should probably be more focused and purposeful. You don’t need to intern, the pros must outweigh the cons. For example some students only seek internships where they share a strong research fit with the team and having specific scientists they want to work with, to compliment their studies rather than distract from it.\nInternships = extended interviews. Assuming your internship went well, the company is now more likely to hire you since you are now familiar to them, no longer an unknown risk: they know what it’s like working with you. This is important and if you’re interested in pursuing a full-time role at this company, you have a much better chance of landing the job. Reason is that precision trumps recall in hiring: an accidental “bad hire” is far worse than missing a “good hire”, so by removing doubt and enabling a company to know that you’d be a good hire already puts you in a strong position.\nJob Search Research Understand your interests and goals. Take some time to introspect and ask yourself the big questions. What excites you? What do you value? What do you want to achieve long term? It can help to think long-term about what you want your career to be about, and brainstorm what you want your life to look like X years from now, or what you want society to look like X years from now, and work back from there. It’s OK to be uncertain about where your skills are better applied, you can factor that in later. Your first step is understanding yourself, your intrinsic motivations, and your sense of purpose. Reflecting on these questions will narrow your search towards sectors or industries you might find interesting. Searching for interesting jobs might sound obvious, but many people do not enjoy their industry jobs, and are there for the money only. But with a grad degree in STEM, you’re hopefully able to find a job that ticks more boxes than just adequate compensation. Ideally, you can find a fulfilling job that you’re passionate about, and pushes you up as many of the stages in the Maslow\u0026rsquo;s Hierarchy of Needs as possible.\nResearch your options. Which companies should you apply to? You can ask colleagues and search online.\n You can compare culture and pay using Glassdoor, Blind, and Levels; with a grain of salt. You can ask colleagues and lab alumni who know you, your skills, and your preferences. You can also cold-email companies that you find interesting. Smaller companies have excellent response rates, and will often set up introductory calls, to discuss fit—especially if you have a PhD—helpful to decide if you want to apply there. Note large companies aren’t homogeneous, there’s certain subgroups you’ll be more interested in than others. Just because you dislike one group in the company, doesn’t mean you’ll dislike all groups. Keep up with the literature in your field and note which companies (and specific research scientists) are actively publishing / participating / sponsoring conferences. If interested in startups, venture capitalists (VCs) can help make connections. To join a pre-existing startup, you can even email VCs with a \u0026ldquo;hey I\u0026rsquo;m a PhD expert in my field looking for a job\u0026rdquo; and they can introduce to you many options that aren’t publicly visible yet. Alternatively, creating a startup might interest you, but this usually involves several rounds of meeting different VCs to find the right VC for your idea (i.e., start with any VC, pitch, then meet their VC contacts they recommend, then meet theirs, and so on for 4–8 rounds, until you find the right VCs for you).  Evaluate companies: As you research different companies, it can help to preemptively begin a decision matrix or “weighted scorecard” on which companies you’d prefer working for. Using a spreadsheet, list each independent quality you care about in an employer, and quantify how much you care about each quality with a weight. Then rate each company out of 10 per quality, summing up to a final, weighted average score. Example:\n Quality Projects People Pay Location Weighted Score  Weight 8 10 8 4 Σ weight × score   Company A 6 8 7 10 224   Company B 10 6 8 6 228   Company C 5–10? 7 7 6 190–230?   While you may not have all the information yet, you now know the relevant questions to ask during your interviews that will later help you make your final decision. For example, Company B looks good, but company C might be worthwhile assuming the projects are sufficiently interesting, so ask about project details of Company C.\nPrepare Website: Have a personal website showing your research. If you don\u0026rsquo;t already have a website, you can host it on your lab’s university page for higher search engine page rank, or GitHub, or your own domain. Traditional CVs still have their place, even in the 2022 tech world, but your online presence also matters: anticipate potential employers googling you, and make sure your website is up to date.\nInterviewing itself is also a great way to job search, to find out about what goes on in different companies. This is especially true for startups which can be quite secretive. They’ll tell you a whole lot about the company that they don’t make public, especially right before you decide who to sign with, people get a lot more loose lipped if they believe it will help you sign. So even if you’re unsure about applying to a company or not, why not apply anyway to learn more? Don’t worry about \u0026ldquo;wasting their time\u0026rdquo;, just be transparent and know that they probably do want to chat. For example you can say \u0026ldquo;for full transparency, only a 5% chance I\u0026rsquo;m actually interested\u0026rdquo; and they might respond \u0026ldquo;no problem! let\u0026rsquo;s chat anyway\u0026rdquo;. You can also reach out to acquaintances in the company to chat, and even a referral; some companies offer their employees bonuses for referrals so they may be inclined to refer you internally even if you’re “only” an acquaintance to them.\nApply Often the most useful way to get insight into the application process is talking to people 1–2 years \u0026ldquo;ahead\u0026rdquo; of you. Ideally recently graduated phds/postdocs from your group for more specific advice to your particular field, background, and interests. The people with the most similar and recent experience to you will give you better calibration. Nevertheless, some more general advice follows.\nHow to start: Apply to 3–10 places you’d like to work. “Like to work” means if only place X gives you an offer, and all other places reject you, you’d likely accept the offer from X (given your current understanding of X, before interviewing). You want multiple offers, since this allows you to negotiate your salary higher than with only one offer by auctioning your labor: having companies one-up each other during negotiations (discussed later). So if you’re not feeling confident, apply to a few more companies.\nWhen to start: Most people start interviewing before their graduation so they have the security of knowing what’s happening next (especially if in the US on a visa), although you don’t necessarily need to do this. Perhaps start 2–4 months before you’d like to sign an offer. Plan to have offers arriving concurrently. This means:\n Timing: Apply to multiple companies approximately at the same time, and schedule interviews at larger companies slightly earlier than others. The hiring process for larger or more established companies typically just take longer, it’s just a law of nature, they have more bureaucracy and take longer to make decisions. Startups will respond faster. Note, however, you do not have full control of timing; some companies will ignore your preferred timelines, but still inform them as there is usually flexibility on their deadlines. Warm up: That said, do not apply to your favorite place first. You need to warm up. If you interview at 1–2 lesser preferred companies first, then you’ll be more relaxed and confident while interviewing for your dream job.  Inform key people: If there’s a particular group you want to work with, email the group’s manager to inform them you are applying. Do not just apply to the generic website interface and wait. Go directly to your would-be-manager. You\u0026rsquo;re much less likely to \u0026ldquo;slip through the cracks\u0026rdquo; unnoticed into a sea of applicants that recruiters try to filter and make sense of if the key technical person (your would-be-manager) gets a nice email from you and knows that you\u0026rsquo;re applying. And if they don\u0026rsquo;t already know you, then briefly outlining which lab you’re coming from or what your research interests are might make them pay more attention if there’s overlap. Managers can get a little annoyed receiving many of these emails, but I promise a brief and polite email will not hurt your chances, it will either help or have no effect. OK, but what if you don’t know who these “key people” are? Well you can find out by:\n Networking in advance Crawl LinkedIn Research the authors of research papers you liked most at that company Ask your professor and lab alumni: many key people are probably only 2 degrees of separation away from you. Professors can vouch for their students if they know people in the company too, it’s in their interest to set their students up for success after time at their lab too.  Apply even if there are no job postings. Just because a company is not advertising positions doesn’t mean they cannot hire you. If there is a particular team or person you want to work with, just email them (or if they don’t respond in 1–2 weeks, try LinkedIn). If you don’t know them, it can help for someone to vouch for you, since managers and team leads get such emails. They may ignore you, they may not. But it doesn’t hurt to try.\nMultiple applications per company? Some larger companies allow you to apply to multiple of their job postings concurrently. They might schedule these in serial, or in parallel. Don’t simply assume you can only apply to one team, or if one team rejects you, that you can’t necessarily apply to another team: verify.\nInterviewing Timeline: If the company decides to proceed with interviews, they may begin with a non-technical filter interview with a recruiter or HR, and then a technical interview. Passing both of these then warrants the company investing more time and effort to assess your skills in depth with a full day onsite series of interviews. Note “onsite” during covid is often virtual. They may have an interview with someone more senior after this, but they are now pretty close to making a decision on whether to send you an offer or not.\nBe positive: An important part of interviewing is figuring out if you’re a good “team fit”, these interviewers are also thinking: “Would I enjoy working with you?” Being positive, polite, and enthusiastic about your own research, and the interviewer’s research if discussed, are easy wins. When candidates present their work as if it bores them (it happens!), they score poorly on the “team fit” evaluation and no one internally champions their candidacy.\nLearn about the company: After any interview questions you are given, you may have the chance to ask any questions about the company, projects, about what working at the company is like. Asking your would-be-colleagues is often a more accurate assessment of what that company is actually like, since they are less incentivized to sugar coat the lifestyle there like your recruiter or would-be-manager is, but will more likely tell you the pros and cons as they see them. Some suggested questions are:\n “What are the long term goals and vision for this team?” “What are you currently working on and what do you want to work on next?” “What is the culture like? Do people work individually more, or in groups?” “Why did you join this company?” “What are the expectations of me, and what are the metrics for employee performance reviews?” “What would my first month and year look like?” “What is the remote / hybrid work policy like?” “How similar / different is the research environment here to an academic research environment?” Asking them to point out the differences can help understand if the work is more product-driven or longer-horizon, and how it might generally differ to your current experiences as a reference point. “Are employees incentivized to publish?” If you do longer-horizon research, you may want to ask about research funding stability. Or asking this more indirectly: \u0026ldquo;How does your team\u0026rsquo;s research fit into the long term vision of the company\u0026rsquo;s goals?” Visas: Some students might start off continuing their student visas and working on an F-1 OPT (with the possibility for a 2-year STEM extension thereafter). The main questions that are important to consider here are usually along the lines of: Will the company sponsor me for an H-1B (the answer is almost certainly yes, it is in their interests to, but good to verify), Will the company sponsor a permanent resident (= green card) application for me? Is there a waiting period where I have to work at the company for X year(s) before they apply for me?  Onsite Congrats, you passed the first couple interviews! You’re now ready for the onsite. An onsite (either in-person or virtual) is often an all-day affair, where you interview with many employees one-to-one in succession.\nCoding interview: Many tech companies have some type of coding interview, and many people practice for this using LeetCode. As a manager, I’ve stopped the practice, since live coding interviews teach me little about the candidate\u0026rsquo;s actual coding ability, in addition to stressing them out (we do walkthroughs together of their prior repos instead). I personally think live coding is a lazy way to filter, favored by larger companies to standardize their interviews (even across engineering and research roles), but I digress. The point is most large tech companies do live coding interviews, so practice beforehand! Read up on those graph search algorithms, hash tables implementation, binary tree manipulation, from your Introduction to Algorithms textbook. Consider reading Cracking the Coding Interview too. For machine learning specific interviews, practice coding the basics like K-means, logistic regression, and possibly dynamic programming style questions if you have a background in control or reinforcement learning. Early startups might not bother with live coding, and tailor their interview process to each candidate more, but whatever the case: know it’s fine to ask a company what type of interviews they\u0026rsquo;ll be giving so that you can do more focused prep.\nTech Talk For research and scientist positions, some companies will offer you the option to do a “tech talk” at the beginning of the onsite day. I highly recommend giving a tech talk, for two reasons:\n You start the onsite from a position of strength: By giving a tech talk before your 1-1s that day, you start from a position of strength by talking about the things that you are expert in. This defines many of the questions you’ll later get during 1-1s that day, drawing many of the questions you’d otherwise receive that day into your area of expertise. Opportunity to communicate your research: If you’re continuing research in industry, continuing to be a researcher, then tech talks are like inviting yourself to mini-workshops talks, where the people listening are highly intelligent, engaged, and will wonder how they might be able to apply your research into their products. You are promoting your work, yourself, and increasing the real-world impact of your research by communicating it to relevant people trying to build products off this kind of stuff.  Tips:\n Simplify: Understand that the people watching your talk are not the same distribution of people watching your talk at an academic workshop specific to your sub-field, or your academic research group. The audience will be more mixed. So explain everything, even the stuff you think is obvious, including high-level motivations, and don\u0026rsquo;t get bogged down in details or benchmarks (companies largely do not care about academic benchmarks). Also, they really love it when you make some connection to the company\u0026rsquo;s work. Even if it\u0026rsquo;s fuzzy or imprecise, do it because it helps them see your work as relevant to them. Tailor: If you’ve just completed your PhD, you have a lot to talk about! Have a chat with your would-be manager to work out what works are most relevant to showcase at your tech talk. Ask yourself: What are the best things you can communicate to this specific group of people? You should highlight your most relevant work for this particular job. The best position you can put yourself into is speaking about something (X) that you know well, that the company doesn’t have expertise in yet, but knows they need expertise in. If you can figure out what X is beforehand, by all means, tailor your talk with this particular company to talk about X in detail. They will fight for you, not only internally to get you an offer, but to give you a competitive offer. Visuals: When communicating performance, don\u0026rsquo;t just screenshot tables from the paper and put them in your presentation. Tables are great for papers, but terrible for presentations. Bar charts (and similar) were designed to compare quantities visually, use them instead to focus on the values that people care about! Also, qualitative results / videos / images usually make more of an impact in people\u0026rsquo;s minds than quantitative numbers. Enthusiasm: For many PhD students at the end of their PhDs, your research might seem repetitive / boring to you since you end up saying the same thing many times (especially if your PhD was a long slog, as it is for many students), but it\u0026rsquo;s important to remember your original passion for the field and bring it to the forefront, enthusiasm is very nice to see in presentations, and a lack thereof can really make an otherwise great presentation boring or raise questions of your desire to work in the field.  1:1s Following your tech talk will be a series of one-to-one meetings, mostly with people you’d be working with. As a manager, there’s some things I’ve noticed that were within the candidate’s control that led to rejections:\n Do:  Admit when you don’t know something well enough to answer. Honesty is a big plus, and we can also move on to new questions. Caveat: Take care to not second-guess yourself too much, too much qualifying can sound like you either don\u0026rsquo;t know much or lack confidence in yourself. You still want to sound confident, which doesn’t mean guessing, and doesn’t mean eluding the question, but being clear and comfortable in voicing what you do and do not know when answering a question. This can take some practice and self-awareness to understand if you speak confidently even when you\u0026rsquo;re not sure, or if you downplay your knowledge. Practice with a friend if you like! Prepare to answer situational and behavioral interview questions (i.e., “tell me about a time when you…”) Ask questions back!  Don’t:  Guess without saying you’re guessing: When people feel you’re making stuff up, it’s a red flag. Similarly don’t evade or reorient questions. Don’t fear (sometimes awkward) pauses. It’s better to consider a question for a few seconds and then delivering a well-thought out response, versus rambling into an answer to avoid any silence. Don’t treat 1:1s with peer-level interviewers less seriously than those with managers or team leads. It can be easy to become more relaxed or casual in these, but it’s important to remember that each individual 1:1 plays a key role in the decision making process.   Rejection No one likes rejection, but expect to receive some rejections. If it helps, everyone gets rejected (and if they didn’t, then they weren’t pushing the envelope of what positions they could plausibly get).\n What it doesn’t mean: Know that many rejections are not so much a reflection on you or your expertise as they are the current state of the hiring company: their current constraints, resources, and vision that are constantly evolving; and the current state of their other candidates. I often meet many awesome candidates that I would want to hire and work with, but headcount limitations and other internal constraints or politics often prevent it. So even though a rejection can hurt, it’s rarely because the company didn’t like you as a person (“team fit”), and it often doesn’t mean they did not value your skills or expertise, there’s often many other variables and hidden constraints behind the curtains. This means you can generally re-apply a year later too, when their situation has changed. Multiple teams: Many companies are not a single homogeneous entity, meaning a rejection from “Team A” might not be a rejection from “Team B”. Different teams usually offer different positions within the same company, for non-small companies, you can often apply to many positions there concurrently, to be assessed independently. Just because one rejected you, doesn’t mean other teams will. If Team A rejects your candidacy, often Team B will not care. I’ve never seen any backchatter about “oooh FYI candidate X was so bad, I doubt you’ll want them on your team”. Instead the opposite: people telling me “this person was great, but not the best fit for our team, but I think your team could unlock their potential”, and I love getting those messages so I can watch out for that candidate. Feedback and moving forward: Rejections aren’t anything to feel ashamed about. I got rejected by Nvidia, Cruise, and Uber. I have no idea why. You can ask for feedback. The feedback I got back from recruiters was vague and generic (possibly because they don’t know, or to ensure no PR or legal repercussions, or because you’re no longer a priority to them). For technical feedback, email the team leads (not recruiter) directly. When I receive these emails as a manager, I try to be as informative as possible, based on what I can and can’t say. Nathan Lambert has a nice visualization about his rejections and acceptances timeline. As you can see, it’s also a numbers game: while you have partial control over boosting your probability of acceptance, you have full control over who you apply to!  Offers If you get this far, congrats! Getting offers from companies is always a great feeling. Now the tables have turned. Now you have the power, and the same interviewers who were previously grilling you, are courting you and trying to convince you to join their team.\nDon’t be pressured: Some companies might give you 7 days to make a decision. This can be a bluff, a bit of a bullying tactic to pressure you into a premature decision, and effective against those fresh from academia who generally underestimate their labor’s worth after years of working long hours for low pay. Or, it could be that the team only has one headcount and another candidate waiting that may disappear soon. Either way, you can often push back on this. You’ll know they’ll need a decision from you soon when the frequency of their calls increases (they are generally very clear with you before they really do withdraw the offer). Most companies expect you’ll need more like a month or more to make a decision.\nVisits: During covid companies may have all their interviews virtually, but afterwards they may still invite you to physically check out the office. To decline this invitation is to communicate that you are highly unlikely to accept their offer, and the company might quietly deprioritize you and your timeline if they have other candidates in their pipeline they are more confident about, which could affect how you negotiate with other companies. You may be fine with this, but it’s nevertheless good to be aware of what effect your responses have during negotiations.\nRequests for salary expectations: Some advise to not reveal your salary expectations (or previous salary) before receiving an initial offer from the company, as you’ll likely underestimate what you can otherwise get. You can politely decline these requests and ask the company to make an offer first (most do anyway), but as long as you get multiple offers you’ll reach your market value either way during negotiation, and any initial guess you made will not ultimately affect your final offer. So don’t worry too much if you slip up here, just make sure you get multiple offers.\nNegotiation Everything is negotiable. You will receive an initial offer from the company. This is not their final offer. If you know to ask for more, you can get it, but you have to ask. Everything in that offer is negotiable too: base salary, retention bonuses, signing bonus, stock, hybrid work format, start date, etc. How far you can push things in your favor is a function of how much they value your skills and experience. Some candidates might be able to negotiate more or less than what you can at the same company. Some companies try to negotiate within certain bounds to avoid grumbling from internal coworkers that you’re being paid significantly more while in the same position at the same company. Other companies do not care and will treat everyone independently. The reality is: once you have unique skills (e.g., from a PhD) the monetary value of your skills is unique. HR might nevertheless try to cluster employees hierarchically into groups with similar positions, titles, and pay; but such compensation fairness only exists to mitigate internal grumbling. If you want to negotiate a higher compensation than what your would-be-coworkers get, a creative way around this is “retention bonuses”, additional to your base pay. HR only cares about keeping base-pay equal-ish. So if you are hitting the limit with base-pay negotiations, try switching to retention bonus negotiation.\nLeverage multiple offers: The easiest way to negotiate your salary is to have multiple offers in hand. Only through leading companies into an auction of your skill and experience can you determine their true market value. When I got my first offer, the compensation package offered was mostly fixed while they were the only buyer. Once I got multiple offers, I could ask for large raises beyond the initial offer, and change the pay/stock ratios, etc. Complaining about Bay-area rent is not as effective as negotiating using a counter offer from a company’s competitor. It’s generally easier negotiating with hard numbers from counter offers than vague complaints about how the Bay area is expensive. Although some people still have success negotiating with single offers. If you only have a single offer, try writing a case for why the company should hire you, and the compensation amount you’re after, and send it to the recruiter. In big companies, the recruiter has to write such a thing anyway to send to the compensation team to justify a high offer, so they will like you for saving them that work.\nLeveraging peers’ offers (ideally peers 1–2 years ahead of you) can help, if you ask nicely what offers they got. This can be useful if the offer you\u0026rsquo;re getting is way less than you expect, or you don\u0026rsquo;t want to go through the process of applying to many companies. Note, this won\u0026rsquo;t have as much power as you leveraging multiple offers of your own.\nGreen card: If you are a US visa holder, you may also be interested in the Green Card (permanent residence) which companies can help you with after X year(s) working with them, so you don’t leave them too soon. X is also negotiable, especially if you have reasons like your partner can only work in the US if you have a green card. That said, you don’t actually need a company to support your green card application—unlike visas which require a sponsor—you can apply for the green card yourself with an immigration lawyer for $5–10k (affordable once you begin your tech salary).\nIt’s worth the effort. Do try to see the negotiation through to the end, even if you don’t like haggling or confrontation. Another five minute phone call can result in bumping your salary another $30k each time you go back and forth between the companies competing for you. From a financial perspective, it is well worth your time: you will rarely see such gains / effort ratios again. Note you’re really negotiating with the finance department, not the team you’ll be working for. Your team doesn’t care how much you get paid, only that you join, so feel free to negotiate firmly and politely to reach your market value. Asking for such increases can seem extreme, even greedy to those used to academic salaries; but it’s important to realize that this is normal in industry and to not sell yourself short.\nRecruiters are on your side: Recruiters are not adversaries during negotiations, even though negotiation can feel slightly adversarial. Good recruiters understand how difficult the decision is for most candidates. They are your advocates and understand that negotiations are complex. Once you pass the interviews, you’re now really working with the recruiter, negotiating together against the company’s finance team to boost your offer. Your technical manager will likely be helping in the background too. It’s neither of their money, they don\u0026rsquo;t care if their multi-billion dollar company has to spend slightly more to get you. They both care about working with you though, and want to make it happen. Understanding this can help frame your communication as \u0026ldquo;helping\u0026rdquo; the recruiter rather than \u0026ldquo;arguing\u0026rdquo; with them. So generally, it helps to provide recruiters with all of the information you are thinking about to make your decisions. Things like relocation status, family decisions and plans, short and long term career goals, things you like about the companies you are interviewing for, things you don\u0026rsquo;t like, etc. Being honest generally allows recruiters to get you the best offer possible and the answers you need to make the decision. No one wants to trick you into joining their company. And regardless if you join or not, it’s all part of growing both of your professional networks (the lengthy conversations can result in getting to know each other well) that you can later use to reach out for career or offer advice later down the track.\n Augmenting the effect: You can augment this effect of recruiters and the team fighting for you internally too by remaining upbeat about the company throughout negotiations: tell everyone you’re speaking to at the company how happy you are to have the offer and how you’d be really happy working there, assuming we can reach a compensation offer that is fair / matches other companies. For example, if company A is offering you $50k more than company B, but you actually prefer company B, tell them this! Tell company B “both companies are great, though I would prefer working at company B, but it’s difficult for me to financially justify given the $50k difference, can you please help me to come close to or match company A”? Company B will love hearing this and they will fight for you. Exception: An exception is startups. At small companies, there are no recruiters. Most likely it\u0026rsquo;s either the CEO or CTO, who really do care about money spent. In these situations, you can leverage the fact that recruiting is time intensive for them. So if they have the option of spending $X more on you, just so that they can save a month of recruiting and work on other higher priority things, that’s a win-win.  Communicating offers: Some applicants are unsure what information they can or should reveal about other offers they’ve received. In general, it’s advantageous to share offer information with recruiters. Recruiters are typically negotiating with three parties: the candidate, the compensation team, and the head of the organization you are interviewing for. The more data and numbers you provide, the better as it allows the recruiter to share competitive offer information internally and make a better case increasing your current offer. At the very least you should be providing the total compensation of your other offers. And it’s usually worth sharing who the offers are coming from too:\n Reasons against: Occasionally company X will say they don’t compete with company Y’s offers. Reasons for: Recruiters and senior engineers have often worked at various places and know more than you about the other institutions (their competitors), and how they compare in terms of culture and tech, to help you understand the difference. Same with the more senior engineers who have worked at multiple companies (everyone switches around every few years). They are not there to bad-mouth competitors, but they often know more about these places than you do, and can talk about the known differences in some ways that may be of relevance for you. Your real enemy here is the “unknown unknowns”, of which you have many. My general recommendation is that, if you’re coming fresh from academia, then you probably don’t know that much about how companies really compare against each other, and you’ll gain a lot more from being open about which other companies you’re interested in and why. It gives people a chance to give you relevant information for you to make a better informed decision, rather than you guessing how places compare. And there’s many dimensions along which companies differ. The best choice for you will unlikely be the best on all criteria (pay, location, etc) so you’ll need to weight the pros and cons, which recruiters and manager can talk through with you (for sure take what company A says about company B with a grain of salt, but remember to also take what company A says about company A with a grain of salt too! Better to have all perspectives (AA, AB, BA, BB) than only AA and BB.  Non-compete agreements: Watch out for any non-compete agreements that lock you out of your main profession and industry for 3–12 months after your first job, stalling your career. Negotiate away any in your contract before you sign. California law already prohibits them, but many other states and nations permit them. They only serve the company\u0026rsquo;s interests, not yours, so don’t sign them.\nStock Most tech companies offer stock as part of your compensation. For a helpful resource to break down the different types and jargon, see the Holloway guide to Equity Compensation. This oftens follows a four year vesting schedule of stock with a one year cliff (meaning no stock if you leave in the first year). Cadence of vesting could be monthly or quarterly depending on the company. Depending on the company, receiving stock is a gamble. Google stock is not a gamble. Private stock (aka stock that you can’t just convert to cash) is a gamble. It can be nice to have some stock, to look forward to “upside” if it skyrockets, but it can also crash and be worthless. You can exchange stock for cash as part of your negotiation. Note stock and cash are often taxed differently too.\nSign-On Bonus Negotiation is primarily about your annual compensation, being the most important thing. That said, at the end of salary negotiation, one final thing I would recommend asking for (or increasing) is a sign-on bonus: a one-off lump-sum payment after signing your employment contract. Especially so if you’re fresh out of grad school without much money to your name yet. Reasons:\n The company can usually justify it (one-off costs are easier to justify internally given their current budget, especially if they are underspending that year, opposed to committing to recurring costs that require estimating uncertain future budgets). A lot of problems magically disappear when you’re not worried about a near-zero bank account. Your “utility of money” curve is steep at this point, and a cash injection can really help you immediately move to a nicer place as you start your new job, and pay a few months rent up front if required. Sign-on bonuses usually dwarf relocation packages in the tech world, so focus on that.  Start Date You may be close to (or experiencing) burn-out after academia. Academia can be punishing. An important consideration for your mental health and general life satisfaction is working out a suitable start date that allows you time to take a well deserved break. This may require a little negotiation, but most employers are flexible on this. Some employers will pressure you to start sooner than you’d prefer, but rarely need you to start as soon as they’re asking. So consider making your signature conditional on being able to take whatever time off you need after graduation. Taking 1–3 months holiday after graduation is completely normal (unless one’s visa situation demands continual employment to retain residency status), but choose whatever is best for you before signing.\n Visa considerations: Timing a start date that gives you some time off as a student on a visa can be a little tricky. You may have some flexibility in choosing the end date of your PhD to mix some vacation and dissertation writing. You may also get a 60 day grace period after completing your program within which you can start your employment, so you can agree with the company to put the start date towards the end of the 60 day grace period (and place this date on your OPT application). However, if you’re not on a student visa, or switching visa types to say H1-B (summer) or O-1 (year round), immigration lawyers may suggest you start asap to increase chances that your new visa application is accepted. In any case, chat to company lawyers about this, you can do this even before signing.  Conclusion How do you tell when negotiations reach their end, do you just keep going back and forth between companies forever? If offers from your top choices are nearly identical or if some subset of your top choices won\u0026rsquo;t match the others after 2+ rounds of negotiation, or when they only increment by $5k each conversation, then you’re near the end. Sometimes recruiters use specific language like \u0026ldquo;this is our best and final\u0026rdquo;. You can ask for their \u0026ldquo;best and final\u0026rdquo; if you\u0026rsquo;re ready to hear it and make your decision.\nDecision While getting multiple offers is a great feeling, and helps you negotiate a better salary, the decision can be bittersweet if you would be excited about working at each of those places. If you are like I was and had trouble deciding, I recommend re-doing the decision matrix exercise (now that you understand each company better and can score each of their qualities more confidently).\n Quality Projects People Pay Location Weighted Score  Weight 8 10 8 4 Σ weight × score   Company A 6 8 7 10 224   Company B 10 6 8 6 228   Company C 8 7 7 6 214   You may find after doing this exercise that the total score aligns with your prior intuition on which company you consciously or subconsciously prefer (e.g., Company B). While your decision isn’t just as simple as a spreadsheet, the exercise of doing so can nevertheless make one feel better about such a big choice when the decision rationale is all laid out explicitly (especially after fine tuning the factor weights to see if that changes which company has the highest overall score, and finding out which quality you’re quite sensitive to, and then thinking about that quality more). It also helps to re-think what you want your life to look like for the next few years, and how this job will position you for your second job in the future.\nPeople, culture, and projects are important qualities to consider. Additional company qualities you may wish to consider and compare between:\n Publishing? Another quality you may want to add to your table is “freedom to publish”, which companies vary wildly on. Some will say “no way”, others will tolerate it but remind you it’s not your #1 priority: their product is. Others will say their CEO must check and either approve or deny with 50% probability, others will say “yes please, and we’ll give you a bonus if you do”. Conversely, lack of obligation to publish may be what you want to assess through discussing role expectations if you want a change after academia. Or even if they don’t allow publishing, do they allow other things like blog posts? Reflect: Before making your decision, a great question from Donald Dansereau is to ask yourself simply: Will you find value in the work? Growth: How well does this help you towards longer career goals? Will you get to work alongside technically adept people in your area that you can learn and grow from? You’re not just choosing a job for its pay and intellectual satisfaction, but as a major investment in yourself and your continual education: will this next role help you pursue your larger, long-term career ambitions? If you don’t know what these are yet, take some time to think about them before making your decision. Networking: How good is this job for networking? Who will your coworkers be, who can you get to know within the company? Work-life-balance: How good is it, will you be happy here, will it be stressful?  More questions? Don’t hesitate to call your would-be-manager or would-be-colleagues if you have a few more questions about the company or what it’s like working there, even if you’ve asked them before, or just to chat about your predicament. Especially so if you’ve completed negotiations and all compensation offers are similar, or the weighted scoring exercise isn\u0026rsquo;t helping, it’s now really about where you want to work. This can be difficult and emotional, but it’s well worth your would-be-manager\u0026rsquo;s time to have this chat with you. Joining is huge for them, chatting for 30–60 minutes a couple times right before your decision is well worth their time.\nInform all companies of your decision: Let all the companies that gave you offers know of your decision. Remember, that by choosing to work for one company, you\u0026rsquo;re not choosing to work for them forever. You may work with these other companies or people later on. People move around every few years too, so it’s good to remain on good terms with those you interviewed with in case you—or they—move and you cross paths again.\nWhile in Industry Remember, the move to industry is not final. It’s easier than ever nowadays to switch back and forth between academia and industry, and even do it concurrently.\nPublish: There’s multiple reasons you may want to keep publishing to consider, including:\n Impact: Your research will have an impact beyond just your company. The whole world can access and use it. Recognition. No CEO can claim your breakthroughs as their brilliance if you publicly author the research for all the world to see. The recognition will follow you as you change companies too, better than “I worked on something NDA-protected at company X, can’t give details sorry”. And while companies may own the intellectual property (IP), everyone knows you generated the IP, and are capable of generating more such IP. That recognition increases your value on the job market. That said, you may not wish to continue publishing, and be free of it, which is obviously fine. While publication can be helpful, remember you can spend your whole life optimizing for a future job. At some point you should just take it.  Read: If you are continuing as a scientist, or even an engineer, a deep and up-to-date understanding of the literature is part of your value in the knowledge economy. Your awareness of technologies and available methods in your field is part of what makes you a great asset to your employer, and helps you get better job offers down the road too.\nNetwork: Make a habit of constantly breaking outside whatever bubble (lab or company) you are currently in. Limiting your “social credit” to only within your current company is to put all your eggs in one basket, which would be risky. Your salary potential is a function of both internal and external networking, so don’t be extreme one way or the other. Some people even make habits of interviewing at new companies every year, even if they don’t plan on leaving their current company, simply to continually understand the current options, and stay sharp with continual interview practice (always ready to do live coding interviews etc). It can instill much confidence when you can be ready at the drop of the hat to switch companies, and know where you could switch to, if you need to.\nFinally: Have fun, hopefully you find a job that’s right for you. And if you feel you chose the wrong job then remember it’s not forever. The great thing about 2022 is that it’s very acceptable for people to move jobs every few years now without it negatively impacting their résumé. In fact, changing companies is often the fastest way to get promotions!\n ","date":1661817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1661817600,"objectID":"4dfa2ba0eff48be72db460a77d84895b","permalink":"https://rowanmcallister.github.io/post/industry/","publishdate":"2022-08-30T00:00:00Z","relpermalink":"/post/industry/","section":"post","summary":"Transitioning from academic research to industry, in the US tech sector","tags":null,"title":"Academia to industry","type":"post"},{"authors":["Rowan McAllister","Blake Wulfe","Jean Mercat","Logan Ellis","Sergey Levine","Adrien Gaidon","Sergey Levine"],"categories":null,"content":"","date":1653436800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1653436800,"objectID":"825e895d99f46fb5298c8e8c1937ad36","permalink":"https://rowanmcallister.github.io/publication/capo/","publishdate":"2022-01-01T00:00:00Z","relpermalink":"/publication/capo/","section":"publication","summary":"Autonomous vehicle software is typically structured as a modular pipeline of individual components (e.g., perception, prediction, and planning) to help separate concerns into interpretable sub-tasks. Even when end-to-end training is possible, each module has its own set of objectives used for safety assurance, sample efficiency, regularization, or interpretability. However, intermediate objectives do not always align with overall system performance. For example, optimizing the likelihood of a trajectory prediction module might focus more on easy-to-predict agents than safety-critical or rare behaviors (e.g., jaywalking). In this paper, we present control-aware prediction objectives (CAPOs), to evaluate the downstream effect of predictions on control without requiring the planner be differentiable. We propose two types of importance weights that weight the predictive likelihood, one using an attention model between agents, and another based on control variation when exchanging predicted trajectories for ground truth trajectories. Experimentally, we show our objectives improve overall system performance in suburban driving scenarios using the CARLA simulator.","tags":["Autonomous Vehicles"],"title":"Control-Aware Prediction Objectives for Autonomous Driving","type":"publication"},{"authors":["Rowan McAllister"],"categories":[],"content":" This post is intended as a guide on how to organize an academic workshop at conferences in the fields of machine learning, robotics, and computer vision. Special thanks to Xinshuo Weng, Erin Grant, Andrea Bajcsy, Thomas Gilbert, Roberto Calandra, Yarin Gal, Pieter Abbeel, Wei-Lun (Harry) Chao for their helpful input, editing, and feedback. All opinions are my own, not necessarily shared.\nGetting Started Purpose Why organize a workshop? Workshops help foster a research community that you care about. Beyond sharing ideas, workshops help communities identify the open questions worth solving and build a sense of what to work on next through group discussions like panels. Such \u0026ldquo;collaborative work\u0026rdquo; and collective brainstorming can help a community make progress towards organizing open questions into short-to-long term topics that are likely impactful and tractable given the field\u0026rsquo;s current state. As an organizer, you can also influence the community\u0026rsquo;s attention towards underappreciated ideas and lesser-known researchers that you think deserve more attention, based on the workshop topic you choose and the keynote speakers you invite.\nA workshop is also a good networking opportunity. For attendees, your venue allows people with similar interests to mingle, share ideas, and socialize. If your workshop is interdisciplinary, it can facilitate cross-pollination of ideas between fields, and if your workshop topic centers on an application, it can build bridges between academia and industry. As an organizer, you’ll meet speakers and authors on friendly terms, having just provided them an additional opportunity to showcase their work. In addition, you’ll get to work closely with organizers from different labs and companies, including researchers from competing companies that you may not have been able to work with otherwise and get to know. Overall, it can be fun and rewarding.\nTopic The first thing to decide when organizing a workshop is: What should your workshop be about? Choose a workshop topic that you are passionate about, that you think is important, and that is timely for the community that you are trying to reach. This often means choosing a novel topic that is not yet mainstream but it is likely to play an important role in the next couple of years. Conversely, choosing a topic that was already explored in past workshops (e.g., a series of workshops on a single topic) requires some thought about how to keep the topic fresh and different from prior years. If you want to continue a topic from prior years, email the organizers from the previous event to see if they are planning to organize the workshop again. No one owns a topic, but it’s easier to collaborate on one proposal than to write competing proposals.\nThe next step is to select the scope. The right scope is a balance between being too broad (too vague to rally people around, or bearing little difference from the conference) and too niche (can’t attract crowds large enough to warrant the venue or have meaningful discussion). I recommend focusing on a family of methods (e.g., offline reinforcement learning or invertible models) or an application (e.g., CV for medicine or ML for climate), but not both (too specific). For example, see past workshop topics at ICRA, RSS, CVPR, NeurIPS.\nOrganizers How to start organizing a workshop? You shouldn’t do it alone since it’s too much work, and being a community event it’s good to have multiple perspectives. So your first step is to recruit co-organizers. Choose your co-organizers carefully, from a range of institutions, subfields, and backgrounds. It works best when organizers have assigned roles, with each organizer taking ownership over some aspect of the workshop (e.g., one of the headers in this document). Assigning responsibilities helps track all the TODOs so none are forgotten in addition to sharing the workload. For example, one co-organizer could be responsible for managing the workshop’s email account and website (easy), another conducting outreach (easy), and another to maintain contact with all your other invited speakers to ensure they are on track to submit the required materials (harder), and another to recruit a program committee and organize reviewing (harder). Discuss and establish roles as soon as possible, ideally before you submit your proposal. Ensure each organizer understands and feels comfortable about their roles too. This will help prevent a few organizers from eventually taking all the responsibilities.\nA critical role is the “lead organizer” to monitor everything at a high level. They can make executive decisions if needed (e.g., amid slow deliberations over email) and delegate incoming or scheduled tasks to ensure nothing falls through the cracks and everything happens on time. Lead organizers receive the most work and stress, being the one ultimately responsible for the workshop. So if you are the lead organizer, it is in your best interest to select co-organizers who you know you can rely on and who will actively and enthusiastically help out. Some workshops designate a “liaison role” to communicate with the conference’s workshop chairs (who oversee venue logistics for all workshops), but since the lead organizer needs to know about all these emails anyway, I find it simpler and faster for the lead organizer to be the liaison themselves.\nThe ideal organizational team is a mix between newer to more experienced organizers. Newer organizers can bring fresh suggestions of formats, themes, and speakers; while more experienced organizers can offer guidance on what works well and have larger networks to reach certain hard-to-reach speakers, recruit a program committee (aka reviewers), or seek other help. Workshop chairs who judge your proposal will be looking for both: newer organizers (less likely to rehash old ideas) while also assessing the organizational experience of the team (so they know you can do it). Some believe adding very senior-career organizers can help chances of workshop approval since their reputation can “legitimize” a workshop. I don’t know how true this is, possibly at IEEE conferences, but don’t count on them to actively help with the low-level details of the workshop. Bringing in new organizers is also a nice way to boost their experiences, resumes, and community presence (especially for more junior students) which is part of your positive impact on the community. But not too many, and you don’t want a team of extremes: half brand-new and half too-senior-to-do-anything. You want a high-entropy distribution over experience, including organizers in-between who know what they are doing and actively helping, guiding, and monitoring. In addition to experiential diversity, geographic and demographic diversity will help you reach more speakers, create a workshop for everyone, and increase chances of your workshop’s approval.\nUnreliable organizers: Occasionally some organizers disappear after you’ve submitted your proposal. It’s not common, but it happens, more likely with a large number of organizers. NeurIPS considers more than 6 to be “too many organizers”, and I agree, unless you’re additionally organizing venues, audiovisuals, or competitions. Too many organizers can lead to a diffusion of responsibility. Any workshop showing 10+ organizers have half those organizers providing zero organizational help. So select 4–6 organizers, who are motivated by the workshop’s success, and clearly establish everyone’s responsibility in your proposal.\nBottom line: Your main priority is finding a reliable, core group of people to help you with either (1) the substantial amount of work ahead or (2) offer reliable guidance, suggestions, and respond to all your questions in a timely manner and help out if you get stuck (e.g. with technical complexities using submission portals etc). So whatever their experience, select co-organizers who really do care about the workshop’s vision and success. If organizers are invested, your workshop will run smoother as organizers will likely think proactively about potential issues before they happen, rather than reacting to issues after they occur. And, if you really want to include any too-senior-to-do-any-work types for reputation points, consider listing them under “advisory committee” on your website, so those in the “organizing committee” don’t feel their recognition is unfairly diluted given their larger workload.\nStart early: To form a reliable organizational team, start 4–6 weeks before the proposal is due. This enables you to gradually enlarge your team: for example, after forming a team of three co-organizers, you may discuss with the team and reach out to a fourth person. Avoid last-minute invitations (e.g., a few days before the proposal due date) for two reasons. First, the newly invited person will not have enough time to provide comments on the proposal and is too late for speaker selection. Second, you may not have enough time to discuss the expected workload with them. This is important if the invitee has no prior experience: they may underestimate the workload and later become less active in the team.\nMoving forwards: Once the organization team is decided, it’s helpful to then video-conference together to discuss initial plans for what the workshop should be about and the rough structure organizers want (e.g. competitions/panels or not). Once a mutual understanding is established, it’s then easier to collaborate asynchronously over email or Google Docs to draft a schedule, add speaker suggestions, and discuss via comments; when preparing the workshop proposal. For multiple shared resources like documents, spreadsheets, slides, and videos; keep it all organized in a shared Drive folder that all organizers have edit access to. After your proposal is accepted, additional meetings prior to events like sending speaker invitations and starting the reviewing phase can help co-organizers stay involved. Without such follow up meetings, the lead organizer might get stuck doing most of the work, unbeknownst to the other organizers.\nProposal Conferences will announce a “call for workshops” analogous to a “call for papers” that you can submit to. The application process mainly involves submitting a 2–5 page PDF proposal on what your workshop would be about and justifying why it’s worthwhile. Depending on the conference, they might accept 30–60% of these applications. So, workshop applications are competitive and it’s worth paying attention to various selection criteria to maximize your chances of acceptance.\nSelection Criteria Read the “call for workshops” (example) carefully, and any additional “guidance” (example) they offer detailing workshop evaluation. Workshop chairs will review your proposal based on criteria close to these, so ensure you have convincing answers to each of the selection criteria that are clear to readers of your proposal. Don’t bury important points on page 5, but present them early, bold keywords if needed so they are impossible to miss. Give special attention to (1) why your topic matters, (2) diversity of speakers and organizers (3) why your workshop is different from previous years if in a series. Note: the second largest NeurIPS workshop BDL was rejected in 2020 after workshop chairs deemed it too similar to their 2019 version). Other reasons NeurIPS 2019 workshops were rejected are outlined here too.\nChecklist: regardless of the conference\u0026rsquo;s guidance, I still make sure to address these following points clearly and in the early pages of my proposals:\n Purpose: Frame your proposal around how your workshop would benefit many attendees at the conference, not only some pre-existing community you care about. The conference will ultimately be selecting proposals around what makes the conference a success and impactful and what benefits its attendees. So clearly outline why the conference would benefit from hosting this workshop and why conference attendees would benefit from attending it. Explain why this topic is important and timely for a subset of the conference community that warrants more focus, and that a workshop at this particular conference would be the ideal venue for them to meet like-minded individuals, make meaningful connections, including between academic and industry, and ultimately create a positive impact on the world (workshop impact means conference impact). Ask yourself: why can\u0026rsquo;t authors just submit their papers to the conference itself; why do they really need to get together as a separate workshop? Diversity of speakers and organizers. When talking about diversity, try not to be vague or generic, otherwise it will seem like your commitment to diversity is in lip service only. I find it helpful to explicitly quantify how diverse our speakers and organizers are, using numbers on the breakdown of genders, race, geographic location, career stage, expertise, and who is new to this particular conference (bringing in outsiders can be a plus). For example, to illustrate career-stage diversity, I’ll say our speakers comprise: 1 student, 2 postdocs, 2 junior faculty, 1 senior faculty, 3 industry; and mention gender diversity like 4 women and 4 men; and geographic, e.g., 4 from the Americas, 2 from Asia, 2 Europe; and categorize their talks into subtopics to show how we’ll get a good coverage of topics throughout the day. You can summarize some of these differences into a table for clarity too (example). Chairs might not have realized this from just reading their names, and may have skimmed their bios, but it is now clear that speakers have diverse career stages, demographics, and locations. Fresh ideas: The proposal should highlight how the workshop will be different to prior related workshops, in terms of theme, format, and maybe some interesting ideas for poster sessions if the conference will be hybrid, etc. Your workshop shouldn’t just rehash the same topics discussed the previous year, but either be an emerging topic or somehow evolved from a prior year with a different focus even if the same topic. How will new organizers contribute to make the workshop different this year given their role? Engagement: Plans to advertise the call for papers, why the community will be excited by this topic, and why they will want to come together on this topic. Concretize this with numbers of related papers in related conferences or number of attendees at the previous or similar workshop. Also, describe how you plan to engage the attendees during the workshop, for example through poster sessions, breakout discussions, online polls at the start/end of the workshop about open questions, a debate, etc. Organizer experience: Highlight what workshops the proposed organizers have previously had experience with. It\u0026rsquo;s good to have organizers that have organized workshops before (to convince the workshop chairs that you know what you\u0026rsquo;re doing) but also that you have newer organizers who may have expertise in new and emerging directions. Solicit participation: Highlight how you’ll plan the call for papers (more important for IEEE conferences). I usually enumerate all the ways I plan to call for papers (see here).  A Fait Accompli Your workshop proposal must instill confidence that you know what you are doing. I find one way to do this is to craft the proposal in such a way that the workshop appears a fait accompli: everything is done and all speakers have confirmed and standing by, your workshop is clearly ready to go, all the workshop chairs need to do now is give permission to proceed! This means:\n Confirmed speakers: Invite all your speakers a month before the proposal is due, to get a list of confirmed speakers to list in your proposal. Emphasize that they are confirmed speakers in your proposal. Note: proposals to IEEE conferences like ICRA and IROS often require proof of each speaker’s conditional participation if the workshop is approved. You can either provide a commitment letter that you prepare and speakers sign, or (easier) a copy/screenshot of speakers’ emails confirming. You can ask the speakers if it’s OK to screenshot their email for this purpose. IEEE conferences also like seeing support or “endorsement”, such as a supporting letter by an RAS Technical Committee member. Schedule: Add a schedule to your proposal, formatted as a table, including specific times and event type. For talks, include the speaker’s name. For example, don’t write “Fourth event: Keynote Speaker 3”, write “10:00am, Keynote Speaker: Jane Doe”. You can always adjust later once speakers update their constraints closer to the date. Website: It helps if the workshop chairs can “see” the workshop they are reviewing. That means creating a website and displaying the URL prominently in your proposal. The website should look as polished as possible. Show the speakers (with images), schedule, organizers, and program committee if you have one, linking names to personal websites in case the workshop chairs want to check them out. Look at other previous accepted workshops for guidance on what a website “should” look like (ICRA, RSS, CVPR, NeurIPS).  As examples, here is our ML4AD 2020 workshop proposal and the NeurIPS 2022 workshop review rubrik.\nSchedule Workshops often have a few types of events, like keynote talks and poster sessions, and possibly lightning talks, panels / debates, and competitions, spread out over a full day. This variety can make the workshop interesting and engaging to attendees. On the day, you’ll never stay perfectly on schedule (e.g. speakers might run over time), so ensure you have some coffee breaks interspersed throughout the day to prevent scheduling delays accumulating too much. Try to avoid last minute changes, but if you have no choice, make sure any schedule updates are reflected in both your workshop website and any conference apps/portals.\nPosters (2+ hours): Posters are the main event of your workshop! Attendees care about their ability to meet others, discuss their work, and discover new research ideas early on, all of which is possible with poster sessions. So schedule sufficient time for posters, they are not an afterthought. Organizers often underestimate how much poster time will work well. On paper, 1–1½ hours of posters might look like a lot, but it is not. Poster sessions take time to build momentum, as audience members find food, coffee, and check messages after talks wrap up (possibly running overtime too). So expect a “40 minute poster session” equals 30 minutes of posters. If you have 15+ posters, aim for 2+ hours of posters. Once people get into the poster sessions, time will fly, and you won’t enjoy breaking up all those interesting discussions prematurely because your schedule has some less-interactive event now starting. I usually schedule joint “posters and coffee” sessions, since people naturally look at posters during coffee—and vice versa—anyway. Consider having at least two poster sessions, e.g. morning and afternoon (in case one conflicts with other conference events etc, and especially for virtual events, to cover different time zones).\nLightning talks: One optional idea is to allow each author to briefly present their work in 1–3 minutes, which serves as an advertisement to attendees to visit their poster during the poster session, assuming you do not have too many authors. This can be more helpful for virtual conferences, since they lack the same serendipity that real poster sessions offer in discovering new works. For smooth transitions between many brief talks, you can request pre-recorded videos for virtual conferences, or use a shared slide deck for in-person presentations.\nKeynotes (4–8 speakers): Scheduling 4–8 speakers is a good bet for full day workshops: you can easily allocate 30–45 minutes to each speaker (for talk + questions) this way and still have time for other events like posters and panels. Schedule each speaker at least 10 minutes for questions so your audience can interact and engage with speakers properly. Interaction is what workshops are all about! Keep in mind speakers often go overtime too, so adequate question time helps act as a buffer.\nDate: sometimes conferences have multiple dates they run workshops on, and workshop chairs will ask for your preferred date. Now that many workshops are going back to a hybrid format with some people physically attending, try to avoid the last day of the conference, since some of those physically attending will leave early and you may have additional speaker scheduling constraints if they fly out that day.\nTimezone alignment: Hybrid or fully-virtual workshops pose extra benefits and challenges. More people are able to attend the event without traveling to the physical conference location, thus increasing your audience, but it can be difficult to satisfy attendee, speaker, and organizer constraints when scheduling events across many time zones. To make your workshop accessible to people from various time zones, consider breaking the schedule into multiple parts, for example by broad geographic location (e.g., Asia, Europe, Americas; example planner), so that most attendees will have at least one workshop component at a convenient time. This is also where having selected a diverse set of organizers and speakers will pay off, since you can more easily ensure coverage of each workshop segment. You can even add Google Analytics to your website to see the geographical distribution of interest in your workshop and select times friendly to where the interest is.\nTimeline Your workshop was approved, congrats! 🎉 Now the real work begins. Your next job is to set up a meeting with your conference co-organizers. The goal of the meeting is to finalize the role assignments and the important dates of your workshop’s timeline: the call for papers date → submission due date → reviewing dates → decision+notification date → camera-ready due date → workshop date. I recommend all deadlines be scheduled at 23:59 (11:59PM) “Anywhere on Earth” timezone (AoE) to reduce confusion. After the meeting, you may also want to send an email to the confirmed speakers, confirming with them that the workshop is accepted.\nCall for papers: Send out a call for papers as soon as you’ve updated your website with your workshop’s timeline, paper format, and submission portal. Post about your workshop sometime Tuesday–Thursday so more people notice it, and then follow up periodically with a few more online reminder posts in the lead up to the deadline (in case people miss the first one).\nSubmission date: Set the submission deadline as late as possible to attract more papers and more recent papers, while still giving enough time for reviewing and then the authors to organize visas after notification. Try to set the deadline after the conference’s notification date to attract conference rejections too (which hopefully improve when submitted to your workshop). Many authors of rejected conference papers still want to attend the conference regardless and submitting to your workshop might still be reason enough for their lab to fund them to go. Avoid setting deadlines that fall on a weekend or common holiday.\nNotification date: If a physical workshop, make sure to set your notification date so authors have enough time to get visas. Some conferences set a “latest date” to notify authors in their call for workshops. Some workshops have “early bird” prices: consider setting workshop decision/notification date to be before the early bird prices stop so authors have a chance to save money. Soon after the notification date (or concurrently) you’ll want to decide on contributed / spotlight talks (if any) so authors have time to prepare.\nSecond submission date? Since selecting a single submission date is an unfortunate compromise between having adequate visa processing time and attracting more papers, some workshops have two rounds of submissions instead. This could be planned, with both submission deadlines advertised together in advance, or an unplanned “deadline extension” if your workshop doesn\u0026rsquo;t receive many submissions initially. A second deadline helps attract more papers. When NeurIPS began requiring early notification dates of all workshops in 2019, their biggest workshop (Deep RL) started including a second call for “late-breaking” papers to attract arXiv submissions popping up after the first deadline. You can decide if late breaking papers should be held to the same standard as the first round of submissions, or if they should represent more exploratory work, maybe less mature with only partially validated preliminary results but nevertheless cutting edge, thought provoking, and novel.\nOutreach: Schedule a set of announcements and reminders about your workshop to social media (Twitter, LinkedIn, Facebook, Instagram) to remind people about your workshop beyond a one-and-done call for papers that people might forget about. Consider assigning the role of “social media czar” to one of your co-organizers so you know it will get done reliably.\n Speakers Speaker Selection How Many? A common mistake new organizers make is inviting too many speakers. Ten speakers might impress those reviewing your proposal, but isn’t necessarily what’s best for your audience. For a full day workshop, 4–8 speakers is good, just ensure you allocate sufficient time for posters. Poster sessions should not be squeezed into your schedule between too many speakers as an afterthought since poster sessions are the main event of your workshop!\nBig Names: Inviting big name speakers is a trade off. Big names can draw big crowds with their brand. However, big names with big responsibilities are more likely to cancel at the last minute when something else more important comes up, or simply repeat a previous talk if they are busy. Exceptions exist of course, some folk are very reliable. So consider only 1–2 big names if you want a larger crowd without taking on excessive risk, and consider scheduling them as “bookends” in your schedule, i.e. last morning speaker and last afternoon speaker, to maximize attendance throughout the day, while minimizing risk: if they cancel, you just finish that session early, avoiding a major schedule disruption. Most invites should ideally be to high-quality, engaged, and “undiscovered” junior researchers. For instance, junior faculty, postdocs, even senior-PhDs; as they are more reliable, more responsive, closer to the tech, and your workshop can have a greater impact on their career while they try to establish themselves, their students, and their labs within the academic community (this is part of your positive impact on the community). Note: some call for workshops list selection criteria including “quality of proposed invited speakers” (NeurIPS language). “Quality” does not mean popular, it means inviting those who can present interesting and impactful scientific discoveries. So consider writing a short summary on each speaker in your workshop proposal giving links to their website, works, and any past talks to support your selection. On the flip side, try to warn brand-new faculty against rehashing their recent job talks since we want more depth, less breath, in our workshop talks.\nFresh Faces: To encourage fresh ideas and fresh faces, I follow a simple rule: no speaker gets reinvited back to the same workshop series. Or if this is a new workshop topic, check who spoke at related workshops in other conferences recently, and select different speakers. This doesn’t always happen, since other organizers have a say too, but I think it’s a nice rule to challenge yourself to seek out speakers you weren’t previously aware of and increase diversity of ideas. Having organizers from different institutions and different nations will help generate a wider set of initial speaker suggestions initially too.\nDiversity: Diversity is important to the community and conference organizers now take this more seriously. Beyond better representing the community and promoting inclusiveness, diversity is a critical selection criteria for workshops, meaning diversity in gender, race, geographic location, subspeciality, and career stage. So think about the set of speakers you want your workshop to have, not just each speaker individually. Optimizing for a set of speakers might require staggered invites as some will agree to speak and some will disagree, so give yourself enough time (4–6 weeks) before the workshop-submission deadline to send out multiple invitation waves to get your confirmed speaker set you can add into your proposal.\nSpeaker Invitations Let newer organizers invite speakers: It’s nice to let newer organizers invite speakers (cc’ing all other organizers) to have a chance at making new connections and build rapport with speakers who might be further along career-wise. If other organizers know the speaker well, they can always chime in afterwards with “hope you can make it Steph!” etc.\nAdd a “respond by” date: When inviting speakers, some don’t respond. If you assume that’s a “no”, and invite someone else as replacement, will the original invitee respond “yes” later? To avoid any awkward situations, add a “please respond by {day, date}” when you send invitations, leaving sufficient time before the proposal is due to invite other speakers.\nIndustry speakers: If you invite industry speakers to your academic workshop, clarify that this is not a marketing pitch and ask that they only accept if they are able to speak about recent technical content. Might sound obvious, but not to everyone. Your audience won’t appreciate a surprise PR show with flashy videos and vague statements about futuristic technology, they want technical detail. Note that many industry speakers require getting their talk approved. So it’s good to ask early, so they can start preparing and getting their talk approved in time for the workshop.\nKeeping in touch: There may be many months between the initial invite and the workshop event. It can be good to occasionally keep them updated with relevant developments (like when your workshop is selected, and when the conference selects which date your workshop will be). Writing update emails to speakers can be a good excuse to remind them of your call for papers (if it’s been called yet) and invite them or their lab to submit works too. Since they are now a part of your workshop, they are more likely to submit papers too.\nPanel You might consider adding a 30–60 minute panel discussion event to your workshop, where you invite keynote speakers back to discuss (or debate) the current state of research. A good panel discussion is both informative and entertaining. To be informative: you want to help people to understand the technical research landscape better, especially newer researchers trying to work out a direction. So consider posing the following questions to the panel:\n When should we use method A over B? What are better ways of thinking about current problems on this topic? What problems are important but currently underexplored (i.e. what research directions might new students and researchers consider pursuing now)?  It can also be fun to poll the community about which discussion topics they would like to see. For example, you can post a poll on twitter about different debate topics.\nPanels can also be entertaining. An experienced moderator is important here, who understands the right questions to ask, to encourage a healthy amount of opinion, jest, and rivalry among competing popular ideas in the field to keep the panelists and audience engaged. A nice format the Bayesian deep learning workshop employed was inviting Yann LeCun as the “Anti-Bayesian” voice to play devil\u0026rsquo;s advocate, disrupting the Bayesians’ echo chamber and (respectfully) challenging other panelists on their fundamental assumptions about Bayesianism and suggesting alternatives to their favorite methods. It makes for a fun and lively debate with points made both philosophical and pragmatic.\nIndustry panelists: Not every industry speaker can speak as freely on certain topics as academic speakers can. Often industry speakers require their internal legal or PR teams to approve their talks and slides in advance, but cannot pre-approve unknown panel questions. So be wary of having too many industry speakers on your panel if your workshop topic centers on an application, or at least ask them what their constraints are in advance.\n Papers Call for Papers There are multiple ways to call on the community to submit papers to your workshop:\n Social (Twitter, LinkedIn, Facebook, Instagram)  Images go great with posts, they are more noticeable. You could use a graphic that represents your workshop’s theme or an image of your confirmed speakers. Tag your speakers and co-organizers, they often want to share and promote it. Tag the host conference in your call for papers post too, using their hashtag or handle (e.g. ICRA’s are #ICRA2022 and @ieee_ras_icra). Conferences often like sharing these to all the conference attendees to promote your workshop.  Mailing lists:  ML news Robotics Worldwide Black in AI (see \u0026ldquo;share opportunities\u0026rdquo;) Women in ML Queer in AI Europe  Institutions: Advertising within each organizer’s lab, university, or company. Individuals you know would be interested.  Paper Format I often copy style files that the conference papers use, editing slightly with a footer that says it’s our workshop. Example style file, tex template, and resultant pdf, stating: “we welcome papers up to 8 pages (max) not including references or appendix, as a single PDF”, and set CMT to only allow one PDF upload per submission (easier for everyone if appendix isn’t separate).\nExtended abstracts: Whatever format you choose, consider allowing 4-page submissions (“extended abstracts”). This is because some computer vision conferences consider peer-reviewed workshop papers exceeding 4 pages as prior publications (e.g. see CVPR or ECCV rules). Extended abstracts (4 pages or less) therefore allow authors to submit preliminary results to your workshop before a conference submission without violating their dual/double submission policy, which are the types of papers you want: exciting up-and-coming ideas that might not even be on arxiv yet.\nSubmissions If you expect 15+ submissions, then use a submission portal to keep track of everything. Options include:\n Conference Management Toolkit (see how-to guide) OpenReview EasyChair  Archival or non-archival? An archival or formally published workshop proceedings often precludes authors from submitting an extended version of the same work to a more formal venue such as a conference or journal. Some authors therefore ask about this so I usually specify on the website that “no submission will be indexed nor have archival proceedings”. In some situations, you may invite submission for both proceedings and non-proceedings. For example, full-length papers go to proceedings, extended abstracts go to non-proceedings.\nReviewing Reviewing submitted papers is optional. I usually provide reviews since feedback is helpful to authors, but not all workshops do. Some workshops like Deep RL were thinking of stopping the practice, and were already lightweight in previous years, largely checking for fit, there being actual content, and a selection of stronger papers for longer presentations. Such lightweight reviewing is more lenient, only rejecting poor or off-topic submissions, corresponding to an acceptance rate of about 90%. Detailed reviewing is more valuable to authors but places more burden on reviewers and can be less practical for larger workshops to provide reviews of consistent quality. If you wish to provide reviews, consider recruiting a program committee (aka reviewers) if you expect 15+ papers, otherwise the organizers can review the papers themselves.\nSingle blind or double blind? Single blind means camera-ready submission can be optional or non-existent if you want to create less work for authors. Double blind is probably more fair.\nProgram Committee Be courteous: To invite people to help review, I find people are much more likely to respond to a personalized invite from a human rather than an automated email from your submission portal. So I usually reach out to people first to ask, and add them into a reviewing system like CMT once they accept and are expecting automated emails (I learned this from Pieter Abbeel, his individual invites to review for the Deep RL workshop were always so polite, I couldn’t say no!). When writing the email, I explain what I’m trying to do, and ask if they’d like to help review. They are busy, and this is “only” a workshop—not a conference—so promise only 1–3 reviews per reviewer (not more than 3) to keep it light, hopefully even fun. Keeping your committee happy means they’ll likely agree to help in future years too. You can also cc your co-organizers on the email to increase the recognition each reviewer receives, though if sending many reviewer invites then consider scheduling the emails to send at the same specific time (gmail can do this) to avoid distracting your co-organizers with a slow trickle of emails.\nHow many reviewers? Aim for 3 reviews per paper so that the majority of papers receive 2–3 reviews. That means inviting about as many reviewers as expected submissions. Tell them the reviewing dates, and follow up with 1–2 polite reminders as the due date approaches to those yet to review. If you do this, only a minority of submissions will receive 0–1 reviews. Many reviewers only do reviews close to the actual deadline, so if you schedule a couple days between the reviewing due date and the notification date, then you can give late reviewers a little more time if they ask for it.\nEmergency reviewers: In anticipation of some papers with 0–1 reviews, you can recruit some “emergency reviewers” in advance to be “on call” for the couple days prior to paper decisions, so that every paper can have at least 2 reviews by the time you made your acceptance/rejection decisions. And if all else fails, you review the papers with fewer than 2 reviews.\nSet expectations: You want to attract novel ideas that are scientifically interesting, on topic, and would create interesting discussions at the workshop. No need to be super critical of experimental results. Workshop papers are not conference papers so communicate to reviewers the criteria you’re looking for.\nReviewer questions: Reviewing shouldn’t be laborious for your program committee, so consider limiting the amount of long-answer fields. If you use CMT, you can customize the review form and add instructions to each field. You even can add the reviewing rubric to your website (example) to help answer submitters’ questions like “my paper contains ABC, but not XYZ, is this good enough for a submission?”. Consider including a score on reviewer confidence too.\nPaper matching: To match reviewers to papers, several tools are available. CMT has some options including random allocation, bidding, or using the Toronto Paper Matching System. Proper matching benefits are nice for authors and reviewers alike, especially if your topic is broad, or is an application (not method) of AI. For small workshops, bidding is probably overkill and takes time, so I manually match reviewers, by looking up their google scholar to classify their expertise in a spreadsheet, then classify the papers into clusters of subtopics on the same spreadsheet, then match like-to-like. Systems like CMT help avoid certain conflicts of interest by preventing you from accidentally matching an author and reviewer from the same institution.\nDecisions You can set the bar for acceptance however you like. Generally workshop decision thresholds are more lenient than conferences, resulting in the acceptance of 50–90% of submissions. I usually aim for three reviews per paper, and then make decisions based on the three reviewer ratings as follows:\n No accept ratings = reject 1\u0026frasl;3 accept ratings = investigate, read reviews thoroughly, organizer makes decision 2\u0026frasl;3 accept ratings = probably accept (check review that rated submission as reject) 3\u0026frasl;3 accept ratings = accept  Keep in mind some reviewers will review in “conference mode” as if these were conference papers, despite any expectations you set initially. Workshop papers are not conference papers (yet). You want to attract new, scientifically interesting ideas; even if the experimental results are premature, or don’t outperform SOTA, or even compare to it yet. So if the idea is on-topic and novel, consider dismissing any reject ratings that were based on lackluster experimental results and comparisons. And finally, if after all that, your count of accepted papers is lower than what you would like, you can do it all again with a second call for papers! Assuming you have time, that is. A second late round isn’t as useful for people who need time for visas, but it’ll increase the average recency of ideas at your workshop.\nNotification: Once you’ve decided which papers to accept and reject, then notify the authors by your promised notification date (which should be on your website). If papers were reviewed, make sure the reviews are viewable by the authors and remind them of the link so they can use the feedback to improve their camera-ready paper if accepted or some other venue if rejected.\nCompetitions You could consider integrating a competition or “challenge” into your workshop. There are two ways to do this:\n You can organize a competition yourself, which requires significant effort; but you retain control, gain recognition, and it can be a great way to launch some new benchmark or dataset you collected and wish to popularize and share. Common competition hosting platforms to use for algorithm evaluation are AIcrowd, CodaLab, EvalAI, and Kaggle. For examples, see the CVPR workshops such as Embodied AI. Alternatively, you can host a competition: invite some group who was hoping to run a related competition anyway and link it up with your workshop (what I do). Hosting should be mutually beneficial: competition organizers are often looking for venues (and sometimes legitimacy) to showcase their winners’ methods and you might be looking for more ways people can engage with your event. Some workshops host multiple competitions, but do consider if your audience really benefits from sitting through multiple competition explanations and award ceremonies. Your audience may prefer more talks or poster time instead.  Competitions are optional, common at computer vision workshops, but not expected. As an idea, in 2021, 54% of CVPR (computer vision) workshops either hosted or organized a competition, compared to 2% at NeurIPS (machine learning), and 0% at RSS (robotics). But that doesn’t mean you can’t incorporate a competition into your own ML or robotics workshop! Our ML4AD was the only NeurIPS workshop to host a competition but we found it rewarding to offer an additional way to engage with our workshop beyond papers and posters without requiring too much of our effort.\nSome conferences host competitions themselves (e.g., NeurIPS has a Call for Competitions). This does not mean that your workshop cannot host its own competition too, it’s a decision for the competition organizers. You won’t benefit much from collaborating with competitions that you are not hosting. If they are strongly on-topic and ask to talk or advertise at your workshop, you could give them 10–15 mins. If you host the competition, then your workshop benefits by bringing their crowd to your venue.\n Event Before the Workshop My checklist:\n Organizer presence: Schedule which organizers will attend the workshop when. Ensure you have 2+ organizers actively monitoring things at any one time for physical or virtual workshops, and 3+ organizers active for hybrid workshops to monitor both the physical and virtual space concurrently. Organizer communication: Setup a private messaging system for communication between organizers, e.g., with slack, so that on the day of the workshop organizers can coordinate quickly (including any remote organizers helping on the virtual side) resolving issues as they arise. Calendar invite for speakers: Make it impossible for your speakers to be confused with timezones by sending them a calender event. Include any Zoom links and the room/location into the event too. This helps if they are running late, and don\u0026rsquo;t have time to find such info buried in their email somewhere. Prepare introductions for each speaker (their bio) for a warm introduction and smooth transitions between speakers. If you are unsure how to pronounce their name, ask them privately in advance. Obtain any consent and release forms (permission to record) from all speakers (keynotes and author talks) supplied to you by any recording groups the conference uses (if any) like SlidesLive. Print messages: To stay on schedule, help speakers avoid going overtime by bringing printed numbers that you can hold up to inform them how many minutes they have left. Print schedules to pin up outside the room (so conference attendees walking outside can check when they might want to join). Spare stuff: Bring spare AV adaptors including Apple adaptors, since AV issues often arise on the day, and spares are useful. Also bring your laptop, USB drives; and spare tape and push pins for posters. Backup questions: Prepare “backup questions” for each keynote or spotlight speaker. When each speaker concludes their talk, you’ll invite questions from the audience, but sometimes they cannot think of anything to ask initially. In such cases, it’s great to have some questions pre-prepared. You can prepare by watching speakers\u0026rsquo; talks in advance if recorded, or reading their recent on-topic papers in advance.  Day of the Workshop It is likely that something will go wrong on the day of your workshop. Redundancy helps here. So have multiple organizers attending the workshop to deal with issues together. If virtual, one of you may lose internet connection, so have 2+ organizers online at any one time. If in-person, carry a spare laptop, AV adapters, and USB drive in case speakers have equipment issues. I have a private schedule with the other organizers who will be the master of ceremonies (MC) when, and who will be watching on standby as “backup MC” ready to take over within a few seconds if something goes wrong (like the MC losing internet connection).\nMy checklist: arrive early and\n Reserve front seats for organizers + speakers. Greet the audio-visual staff to understand how everything will work, and explain any signals they’ll be gesturing toward you from the back when you’re up at the front talking during the day. There’s often AV issues on the day (a speaker doesn’t have the right adapter etc) and the AV team is critical here, so it’s good to get to know them, and thank them at your workshop’s conclusion.  Poster Sessions Attend your own workshop! Go chat to authors during the poster sessions and learn about their work. As an organizer, I recommend visiting posters that are not receiving as much attention. People are social, and crowds assume social proof that certain posters are better if people are there, creating unequal distributions of crowded posters and lonely posters. You can counteract this bias by visiting less populated posters, which will attract others.\nTalks Even if you prepared “backup questions” for each speaker in advance, for non-recorded talks, you’ll want at least one organizer (the MC) to be paying attention to each speaker during the event to think of backup questions live. If no one asks a question, then you can ask your backup question. Questions beget questions too, it will warm up the audience. This is especially helpful for virtual conferences. Virtual attendees often prefer typing questions too, so remind the audience they can type their questions into the Zoom chat or question field during the talk, so you can immediately begin the Q\u0026amp;A after.\nAfter the Workshop After the event, there’s several options to consider\n Thank audio-visual staff: After the workshop, thank the audio-visual staff and consider adding their names to the website. They do much critical work behind the scenes. Get feedback, e.g., via a link on your website or email to improve next year (example). Dinner: You can organize a dinner for the speakers and (if you have them) sponsors. This is nice for the speakers, and a good opportunity to get to know them better. It can be a bit pricey to buy a dinner for ~10 people, but one of your sponsors may be happy to pay the bill. Have some time between the workshop end and dinner though, people often want a break, or want to chat to others after the workshop instead of rushing off to dinner straight away. Link recordings to the website. It’s nice for speakers to have public links to their talks and for others who couldn’t make your event to see. Summarize submissions: Some organizers like writing up a paper or blog or website to summarize the workshop, something easily spread on social media. This helps give further publicity to workshop papers and the workshop itself. One group actually wrote a blog summarizing my own workshop without me which was amusing. At ICCV we wrote a summary paper after the event. Most workshops do not bother with this, this is very optional.  Website You’ll need a webpage, to summarize the speakers, schedule, and how to submit papers.\nAccessibility: Not all websites are accessible to everyone. Google Sites is very easy to use, but not accessible in China. GitHub Pages is a little harder to use, but accessible in more countries.\n Custom URLs: Alternatively, you can provide custom URLs to make certain sites accessible. For example https://www.icra2022av.org (accessible in China) is actually this website under the hood https://sites.google.com/view/icra2022av/home (inaccessible in China), so we just communicate the .org domain version. You can do this by going to your google site, then settings→ custom domains → add → buy a domain (~$12 a year). Github or Google Sites? An advantage of google sites: quick to create + upkeep, for anyone in team. Advantage of github: get more control on appearance and enable javascript. For example, people can get confused with timezones, so I always use the “Anywhere on Earth” (AoE) timezone, and include a javascript countdown so people know exactly when the deadline is, or linking to https://time.is/Anywhere_on_Earth. For github I used this template which looks like this initially, which I change to look like this. Or use GitHub Pages which is simpler, looks like this; or http://jekyllrb.com/ which looks like this. An advantage of github is you can upload and host papers directly on your website. Other: You could also host and manage websites using Amazon S3 buckets  Timezone help: To help virtual attendees avoid doing timezone conversations themselves, you can display the time of each section of the workshop in multiple major time zones on your website’s schedule, or use javascript to display event times in the attendee\u0026rsquo;s local timezone (example). You can also include an ICS-formatted calendar they can download too (example). Or assuming most people use Google Calendar, you can add one-click invites per event. To do this, first add a new workshop calendar, then click calendar options →check “Make available to public” check true (details). Second, publish each event individually (click three dots for the Options menu, click “Publish event”, copy “Link to event”). Another alternative when using a github webpage, is to include a javascript “venue time” clock (local time at the venue) on the schedule.\nHelpful Tips / FAQ: If the workshop is physical, I often like to add suggestions where authors can print their posters near the venue (easier for one person googling this than 50). Some workshops even include poster templates.\nStreaming: Add a streaming link on your website if the conference allows it. For example, you can stream your Zoom meeting on YouTubeLive.\nVirtual Tools Streaming talks:\n SlidesLive (example) Twitch Zoom Pro YouTubeLive (note you must sign up for this at least 24 hours in advance: it takes 24 hours exactly between you requesting to stream with Youtube and it being enabled) Via Zoom (instructions) (example) Streaming talks without interaction  CrowdCast Facebook Live   Streaming questions with upvoting + moderation:\n Slido (how-to video) Pigeonhole Live (how-to videos) Mentimeter (how-to video) Zoom Q\u0026amp;A Slack RocketChat (used at ICLR)  Poster Sessions:\n Gather Town and Spatial Chat: 2D avatar environments  Join by browser, no installation required. Can upload poster images and link to videos (our example) Proximity-based audio+visuals to other avatars. Gather Town is very popular, many people are used to it now.  Mozilla Hubs, a 3D avatar environment (our example) (how-to videos)  Join by browser, no installation required. Posters should be imported as images, since pdf rendering is poor. Use a larger font size than you would for a regular poster. Importing videos renders well. Used at IEEE-VR conference  Microsoft Teams Hopin Note: per-author Zoom links are generally a bad idea, the lack of serendipity leads to many lonely rooms.  Sponsorship Workshop sponsorship is optional. Sponsors can contribute cash, cloud credits, or hardware. Some workshops use sponsorship to fund best paper awards. Although, I doubt prize amounts not exceeding the cost of travel provide extra motivation to submit. Researchers are already motivated to submit papers and often best-papers are won by well-funded labs already. In my opinion, it\u0026rsquo;s better to fund student travel awards based on financial need, to enable more people to attend your workshop or at least reduce the financial stress of doing so (example application). It helps create a more equal research community and can increase physical attendance. However, workshop sponsorship is often more trouble than it’s worth, for reasons below. An exception is for competitions, which usually require prizes to generate initial interest.\nWarning: handling funds can be difficult. If you have multiple sponsors, then holding funds together can be difficult. You cannot hold funds in your own personal bank account. You can open a new bank account, or you can ask a trusted third party like a university to hold funds for you, for a fee (e.g. Toronto might if you’re a student/staff there, Berkeley won’t unless the event is on campus). The easiest option I find is to ask sponsors to transfer to recipients directly without involving third parties. When companies want to sponsor using their corporate credit card, use PayPal. PayPal is the easiest way to make international card transactions to individuals, and works in almost every country. If the sponsor requests an invoice for internal accounting purposes, I use one of these templates. If the sponsor is US based, they might request collecting W-9 or W-8BENE tax forms for US and non-US prize winners.\nEnsure fairness and consider sponsor constraints. Hardware companies might sponsor by handing you a GPU or laptop at the event to hand to winners on stage (be careful during Covid though, some US companies can only ship to certain regions: US/Canada/Europe/Africa, but not Asia, not even to Asia indirectly via your address, due to government sanctions). Whoever your sponsor is, be very clear about what their constraints are and what strings they want to attach in advance. For example, some sponsors stipulate the winner must be from a university. Also inquire if there are any nationalities they cannot transfer to (especially if they sponsor computer hardware as a prize), and if they cannot sponsor winners from certain nationalities that you’d expect at your workshop (e.g. because of sanctions or company policy), then drop the sponsor. Note: they may not exactly be upfront about these international constraints (bad PR), so you should inquire and verify. And they may be unwilling to say over email, but might tell you over video call. But if they ever tell you “check with us before you choose who to award the prize”, do not allow them to sponsor, as there is something that they are not telling you. You must ensure that your process of selecting prize winners is fair, and not conditional on unknown sponsor constraints.\nOther considerations. Sponsors might also request proof that prize recipients are in fact the competition or best-paper winners. Emails and websites might not count as proof, but event video recordings probably will. Find out in advance!\n Appendix Website JavaScript Submission Countdown \u0026lt;p\u0026gt;Submissions due: 1st January 2022 at 23:59 Anywhere on Earth: \u0026lt;span id=\u0026quot;countdown\u0026quot;\u0026gt;\u0026lt;/span\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;script\u0026gt; // Set the date we're counting down to var countDownDate = new Date(\u0026quot;Jan 1, 2022 23:59:59 UTC\u0026quot;).getTime(); // enter time here in AoE countDownDate = countDownDate + 1000 * 3600 * 12 // AoE = UTC - 12 // Update the count down every 1 second var x = setInterval(function() { // Get today's date and time var now = new Date().getTime(); // Find the distance between now and the count down date var distance = countDownDate - now; // Time calculations for days, hours, minutes and seconds var days = Math.floor(distance / (1000 * 60 * 60 * 24)); var hours = Math.floor((distance % (1000 * 60 * 60 * 24)) / (1000 * 60 * 60)); var minutes = Math.floor((distance % (1000 * 60 * 60)) / (1000 * 60)); var seconds = Math.floor((distance % (1000 * 60)) / 1000); // Display the result in the element with id=\u0026quot;countdown\u0026quot; var countdown = days + \u0026quot;d \u0026quot; + hours + \u0026quot;h \u0026quot; + minutes + \u0026quot;m \u0026quot; + seconds + \u0026quot;s \u0026quot;; // If the countdown is finished, write some text if (distance \u0026lt; 0) { clearInterval(x); countdown = \u0026quot;Hurry, submissions closing soon!\u0026quot;; // optional message if countdown expired } document.getElementById(\u0026quot;countdown\u0026quot;).innerHTML = countdown }, 1000); \u0026lt;/script\u0026gt;  Display Live Venue Time in Schedule \u0026lt;p\u0026gt;All times are in Pacific Time. Current time is \u0026lt;span id=\u0026quot;pacifictime\u0026quot;\u0026gt;\u0026lt;/span\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;script\u0026gt; // Update the count down every 1 second var x = setInterval(function() { var d = new Date(); var n = d.toLocaleTimeString(\u0026quot;en-US\u0026quot;, {timeZone: \u0026quot;America/Los_Angeles\u0026quot;, hour: '2-digit', minute:'2-digit', hour12: false}) document.getElementById(\u0026quot;pacifictime\u0026quot;).innerHTML = n }, 1000); \u0026lt;/script\u0026gt;  Display Schedule Events in User\u0026rsquo;s Timezone \u0026lt;p\u0026gt; Keynote talk by Alice at \u0026lt;span id=\u0026quot;keynote1_time\u0026quot;\u0026gt;\u0026lt;/span\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt; Keynote talk by Bob at \u0026lt;span id=\u0026quot;keynote2_time\u0026quot;\u0026gt;\u0026lt;/span\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;script\u0026gt; // specify schedule in UTC const keynote1_utc = new Date('May 10, 2022 10:00 GMT+00:00'); const keynote2_utc = new Date('May 10, 2022 11:00 GMT+00:00'); // displays in the user's local timezone document.getElementById(\u0026quot;keynote1_time\u0026quot;).innerHTML = keynote1_utc; document.getElementById(\u0026quot;keynote2_time\u0026quot;).innerHTML = keynote2_utc; \u0026lt;/script\u0026gt;  Sources This advice comes from colleagues and my own experience co-organizing the following workshops:\n ICLR 2019 Task-Agnostic Reinforcement Learning NeurIPS 2019 Machine Learning for Autonomous Driving RSS 2020 Interaction and Decision-Making in Autonomous-Driving ICML 2020 AI for Autonomous Driving ECCV 2020 Perception for Autonomous Driving NeurIPS 2020 Machine Learning for Autonomous Driving ICCV 2021 Multi-Agent Interaction and Relational Reasoning ICCV 2021 Autonomous Vehicle Vision NeurIPS 2021 Machine Learning for Autonomous Driving ICRA 2022 Fresh Perspectives on the Future of Autonomous Driving NeurIPS 2022 Machine Learning for Autonomous Driving  ","date":1652140800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1652140800,"objectID":"76ca418c1be6912035b33bf0568a7423","permalink":"https://rowanmcallister.github.io/post/workshops/","publishdate":"2022-05-10T00:00:00Z","relpermalink":"/post/workshops/","section":"post","summary":"Advice on workshop organization at academic conferences","tags":null,"title":"Workshop organization guide","type":"post"},{"authors":["Blake Wulfe","Ashwin Balakrishna","Logan Ellis","Jean Mercat","Rowan McAllister","Adrien Gaidon"],"categories":null,"content":"","date":1643068800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1643068800,"objectID":"28472646a894a9e3df7e2e4fa70840c4","permalink":"https://rowanmcallister.github.io/publication/dard/","publishdate":"2022-01-25T00:00:00Z","relpermalink":"/publication/dard/","section":"publication","summary":"The ability to learn reward functions plays an important role in enabling the deployment of intelligent agents in the real world. However, comparing reward functions, for example as a means of evaluating reward learning methods, presents a challenge. Reward functions are typically compared by considering the behavior of optimized policies, but this approach conflates deficiencies in the reward function with those of the policy search algorithm used to optimize it. To address this challenge, Gleave et al. (2020) propose the Equivalent-Policy Invariant Comparison (EPIC) distance. EPIC avoids policy optimization, but in doing so requires computing reward values at transitions that may be impossible under the system dynamics. This is problematic for learned reward functions because it entails evaluating them outside of their training distribution, resulting in inaccurate reward values that we show can render EPIC ineffective at comparing rewards. To address this problem, we propose the Dynamics-Aware Reward Distance (DARD), a new reward pseudometric. DARD uses an approximate transition model of the environment to transform reward functions into a form that allows for comparisons that are invariant to reward shaping while only evaluating reward functions on transitions close to their training distribution. Experiments in simulated physical domains demonstrate that DARD enables reliable reward comparisons without policy optimization and is significantly more predictive than baseline methods of downstream policy performance when dealing with learned reward functions.","tags":["Reinforcement Learning"],"title":"Dynamics-Aware Comparison of Learned Reward Functions","type":"publication"},{"authors":["Rowan McAllister"],"categories":[],"content":" Choosing the right research problem is difficult. Both Vladlen Koltun and Richard Hamming offer some great advice on selecting which research problems to work on and how. This post is simply a summary of Richard\u0026rsquo;s talk \u0026ldquo;You and Your Research\u0026rdquo;, and Vladlen\u0026rsquo;s talk \u0026ldquo;Doing (Good) Research\u0026rdquo;, both worth watching in their entirety!\nProblem Progressing from undergrad into research can seem to flip any STEM field from a science into an art: undergrads identify solutions to problems versus researchers who identify problems worth solving. The right problem is ill-defined, yet critical to identify.\nDefine \u0026ldquo;right\u0026rdquo; Richard: right is simply subjective, up to you.\nVladlen: right should:\n Contribute to the progress and well-being of humanity, should be useful. Maximize your contribution to the research community and society (not vice versa) by  inspiring the community; shifting the way the community thinks about existing problems (or new ones); be a methodical evaluation of methods to demonstrate which should be used when; be a dataset, benchmark, or open source code people find useful.   How to work on the \u0026ldquo;right\u0026rdquo; problems  Create a long term vision to guide yourself (not a random walk), have high-level meta goals.  Ask yourself: what fields or applications do you find interesting or meaningful and why? You\u0026rsquo;ll only really succeed in work that you enjoy. Doing meaningful work helps avoid burnout.  Understand what components are needed for your high-level goals to become a reality. Understand the state-of-the-art for each component by reading and doing (explained later).  Analyze bottlenecks. Understand what you could do to benefit the collective progress of the community.  Solve a component\u0026rsquo;s problem if the time is right.  Too early = not sufficient tools to attack the problem well yet, will make little headway. Too late = you won\u0026rsquo;t contribute to affecting the research community\u0026rsquo;s direction much, improvements will be too incremental.   Understand by reading  Read a lot. Read critically. When reading about a new method, ask:  What are its limitations and assumptions, when will it break? What gaps remain?  Reading critically enables new ways of thinking about methods. Otherwise you won\u0026rsquo;t make big changes, you\u0026rsquo;ll merely extend the old with incremental improvements. So tolerate some subjective uncertainty about the \u0026ldquo;accepted methods\u0026rdquo;. Be sufficiently skeptical to perceive flaws and see what others missed. It\u0026rsquo;s OK to be (justifiably) contrarian! Inform your colleagues about your research interests. They\u0026rsquo;ll give you greater observability of the relevant papers you should read (but missed).  Understand by doing  Re-implementation is the best way to understand a method. You\u0026rsquo;ll discover details you can\u0026rsquo;t glean from just reading, and develop deeper insight. Implementation helps observe things you never set out to discover. And by following the scientific method down this rabbit hole, you can then go about testing assumptions about what generated the effect you observed. Research then begets research: the more things you try, the more you observe, the more things you want to try next etc, the more people will want to collaborate with you, and invite you to things, and tell you about things you didn\u0026rsquo;t otherwise know. Be methodical when (re-)implementing: swap a method\u0026rsquo;s subcomponents in and out in a controlled way to understand which components were critical.  Understand by writing  Write down your ideas + experimental methods early. This makes clear what your assumptions are and what gaps remain to be filled. You can also share this (more concrete) document of your ideas with your peers.  Work ethic  Luck favors the prepared! Research is 99% perspiration, 1% inspiration. Newton thought if people just worked as hard as he did, they\u0026rsquo;d get the same result. Great researchers always think about problems, even when they\u0026rsquo;re away from work. Set aside quiet time reflection time for “great thoughts” like Friday afternoon to:  Think higher-level about where you are heading, is this the right direction? Don\u0026rsquo;t cling to bad ideas too long, know when to walk away / bury work.  Have 10\u0026ndash;20 problems in your head at any one time, so you don\u0026rsquo;t stay \u0026ldquo;stuck\u0026rdquo; in one problem. When a clue comes along for one of them, focus on it. Have an open door policy (need to collaborate), it\u0026rsquo;s better in the long run. Learn how to communicate your ideas in a formal and casual way. Be on the lookout for collaborators. Quality over quantity (do not add noise to conferences or arXiv, or worse: mislead).  Contribution is the goal, the publication process is a liability.  Confidence is necessary: it is important that you believe you can do great work.  Challenging yourself  Ask yourself: if what I\u0026rsquo;m doing is not important, and not likely to lead to important things in the future, why am I working on it?  Caveat: not to say adopt \u0026ldquo;Nobel prize winner syndrome\u0026rdquo; of only working on \u0026ldquo;great problems\u0026rdquo; and getting nowhere. Instead, work on small acorns that have the potential to grow into mighty oaks.  Ask yourself: what are the most important problems in my field? Be willing to accept change, don\u0026rsquo;t stick to a particular method.  Warnings  Sometimes the people around you cannot see you\u0026rsquo;re doing great work.  A printer-friendly version of this post is here.\n","date":1635206400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1635206400,"objectID":"8db034acdc3224abf38808ba0cf1d04a","permalink":"https://rowanmcallister.github.io/post/research/","publishdate":"2021-10-26T00:00:00Z","relpermalink":"/post/research/","section":"post","summary":"Choosing the *right* research problem + how to succeed","tags":null,"title":"How to do research","type":"post"},{"authors":["Boris Ivanovic","Kuan-Hui Lee","Pavel Tokmakov","Blake Wulfe","Rowan McAllister","Adrien Gaidon","Marco Pavone"],"categories":null,"content":"","date":1619481600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1619481600,"objectID":"8f458a2b1a1f0cbc4370997c8ae9362d","permalink":"https://rowanmcallister.github.io/publication/haicu/","publishdate":"2021-04-27T00:00:00Z","relpermalink":"/publication/haicu/","section":"publication","summary":"Reasoning about the future behavior of other agents is critical to safe robot navigation. The multiplicity of plausible futures is further amplified by the uncertainty inherent to agent state estimation from data, including positions, velocities, and semantic class. Forecasting methods, however, typically neglect class uncertainty, conditioning instead only on the agent’s most likely class, even though perception models often return full class distributions. To exploit this information, we present HAICU, a method for heterogeneous-agent trajectory forecasting that explicitly incorporates agents’ class probabilities. We additionally present PUP, a new challenging real-world autonomous driving dataset, to investigate the impact of Perceptual Uncertainty in Prediction. It contains challenging crowded scenes with unfiltered agent class probabilities that reflect the long-tail of current state-of-the-art perception systems. We demonstrate that incorporating class probabilities in trajectory forecasting significantly improves performance in the face of uncertainty, and enables new forecasting capabilities such as counterfactual predictions.","tags":["Autonomous Vehicles"],"title":"Heterogeneous-Agent Trajectory Forecasting Incorporating Class Uncertainty","type":"publication"},{"authors":["Nicholas Rhinehart","Jeff He","Charles Packer","Matthew Wright","Rowan McAllister","Joseph Gonzalez","Sergey Levine"],"categories":null,"content":"","date":1618963201,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1618963201,"objectID":"33769b280296f33a6a29a3d139c7d660","permalink":"https://rowanmcallister.github.io/publication/contingency/","publishdate":"2021-04-21T00:00:01Z","relpermalink":"/publication/contingency/","section":"publication","summary":"Humans have a remarkable ability to make decisions by accurately reasoning about future events, including the future behaviors and states of mind of other agents. Consider driving a car through a busy intersection, it is necessary to reason about the physics of the vehicle, the intentions of other drivers, and their beliefs about your own intentions. If you signal a turn, another driver might yield to you, or if you enter the passing lane, another driver might decelerate to give you room to merge in front. Competent drivers must plan how they can safely react to a variety of potential future behaviors of other agents before they make their next move. This requires contingency planning, explicitly planning a set of conditional actions that depend on the stochastic outcome of future events. Contingency planning outputs a policy that is a function of future timesteps and observations, whereas standard model predictive control-based planning outputs a sequence of future actions, which is equivalent to a policy that is only a function of future timesteps. In this work, we develop a general-purpose contingency planner that is learned end-to-end using high-dimensional scene observations and low-dimensional behavioral observations. We use a conditional autoregressive flow model to create a compact contingency planning space, and show how this model can tractably learn contingencies from behavioral observations. We developed a closed-loop control benchmark of realistic multi-agent scenarios in a driving simulator (CARLA), on which we compare our method to various noncontingent methods that reason about multi-agent future behavior, including several state-of-the-art deep learning-based planning approaches. We illustrate that these noncontingent planning methods fundamentally fail on this benchmark, and find that our deep contingency planning method achieves significantly superior performance.","tags":["Autonomous Vehicles","Planning"],"title":"Contingencies from Observations: Tractable Contingency Planning with Learned Behavior Models","type":"publication"},{"authors":["Tim Rudner","Vitchyr Pong","Rowan McAllister","Yarin Gal","Sergey Levine"],"categories":null,"content":"","date":1618963200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1618963200,"objectID":"82e24aa42db734293b21b3a81f1dddd0","permalink":"https://rowanmcallister.github.io/publication/goals/","publishdate":"2021-04-21T00:00:00Z","relpermalink":"/publication/goals/","section":"publication","summary":"While reinforcement learning algorithms provide automated acquisition of optimal policies, practical application of such methods requires a number of design decisions, such as manually designing reward functions that not only define the task, but also provide sufficient shaping to accomplish it. In this paper, we discuss a new perspective on reinforcement learning, recasting it as the problem of inferring actions that achieve desired outcomes, rather than a problem of maximizing rewards. To solve the resulting outcome-directed inference problem, we establish a novel variational inference formulation that allows us to derive a well-shaped reward function which can be learned directly from environment interactions. From the corresponding variational objective, we also derive a new probabilistic Bellman backup operator reminiscent of the standard Bellman backup operator and use it to develop an off-policy algorithm to solve goal-directed tasks. We empirically demonstrate that this method eliminates the need to design reward functions and leads to effective goal-directed behaviors.","tags":["Reinforcement Learning"],"title":"Outcome-Driven Reinforcement Learning via Variational Inference","type":"publication"},{"authors":["Angelos Filos","Panagiotis Tigas","Rowan McAllister","Nicholas Rhinehart","Sergey Levine","Yarin Gal"],"categories":null,"content":"","date":1593129600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1593129600,"objectID":"f76a56afb594d0a3f687c1bb0a09c6a7","permalink":"https://rowanmcallister.github.io/publication/carnovel/","publishdate":"2020-06-26T00:00:00Z","relpermalink":"/publication/carnovel/","section":"publication","summary":"Out-of-training-distribution (OOD) scenarios are a common challenge of learning agents at deployment, typically leading to arbitrary deductions and poorly-informed decisions. In principle, detection of and adaptation to OOD scenes can mitigate their adverse effects. In this paper, we highlight the limitations of current approaches to novel driving scenes and propose an epistemic uncertainty-aware planning method, called robust imitative planning (RIP). Our method can detect and recover from some distribution shifts, reducing the overconfident and catastrophic extrapolations in OOD scenes. If the model's uncertainty is too great to suggest a safe course of action, the model can instead query the expert driver for feedback, enabling sample-efficient online adaptation, a variant of our method we term adaptive robust imitative planning (AdaRIP). Our methods outperform current state-of-the-art approaches in the nuScenes prediction challenge, but since no benchmark evaluating OOD detection and adaption currently exists to assess control, we introduce an autonomous car novel-scene benchmark, CARNOVEL, to evaluate the robustness of driving agents to a suite of tasks with distribution shifts.","tags":["Autonomous Vehicles"],"title":"Can Autonomous Vehicles Identify, Recover From, and Adapt to Distribution Shifts?","type":"publication"},{"authors":["Amy Zhang","Rowan McAllister","Roberto Calandra","Yarin Gal","Sergey Levine"],"categories":null,"content":"","date":1592438400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1592438400,"objectID":"26c6495452d6301b8d38e8514d2f8d2a","permalink":"https://rowanmcallister.github.io/publication/dbc/","publishdate":"2020-06-18T00:00:00Z","relpermalink":"/publication/dbc/","section":"publication","summary":"We study how representation learning can accelerate reinforcement learning from rich observations, such as images, without relying either on domain knowledge or pixel-reconstruction. Our goal is to learn representations that both provide for effective downstream control and invariance to task-irrelevant details. Bisimulation metrics quantify behavioral similarity between states in continuous MDPs, which we propose using to learn robust latent representations which encode only the task-relevant information from observations. Our method trains encoders such that distances in latent space equal bisimulation distances in state space. We demonstrate the effectiveness of our method at disregarding task-irrelevant information using modified visual MuJoCo tasks, where the background is replaced with moving distractors and natural videos, while achieving SOTA performance. We also test a first-person highway driving task where our method learns invariance to clouds, weather, and time of day. Finally, we provide generalization results drawn from properties of bisimulation metrics, and links to causal inference.","tags":["Reinforcement Learning"],"title":"Learning Invariant Representations for Reinforcement Learning without Reconstruction","type":"publication"},{"authors":["Suneel Belkhale","Rachel Li","Gregory Kahn","Rowan McAllister","Roberto Calandra","Sergey Levine"],"categories":null,"content":"","date":1587600000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1587600000,"objectID":"f249819bd4b58080e78a19725f59b8e3","permalink":"https://rowanmcallister.github.io/publication/meta-mbrl/","publishdate":"2020-04-23T00:00:00Z","relpermalink":"/publication/meta-mbrl/","section":"publication","summary":"Transporting suspended payloads is challenging for autonomous aerial vehicles because the payload can cause significant and unpredictable changes to the robot's dynamics. These changes can lead to suboptimal flight performance or even catastrophic failure. Although adaptive control and learning-based methods can in principle adapt to changes in these hybrid robot-payload systems, rapid mid-flight adaptation to payloads that have a priori unknown physical properties remains an open problem. We propose a meta-learning approach that ``learns how to learn'' models of altered dynamics within seconds of post-connection flight data. Our experiments demonstrate that our online adaptation approach outperforms non-adaptive methods on a series of challenging suspended payload transportation tasks.","tags":["Reinforcement Learning"],"title":"Model-Based Meta-Reinforcement Learning forFlight with Suspended Payloads","type":"publication"},{"authors":["Brijen Thananjeyan","Ashwin Balakrishna","Ugo Rosolia","Felix Li","Rowan McAllister","Joseph Gonzalez","Sergey Levine","Francesco Borrelli","Ken Goldberg"],"categories":null,"content":"","date":1559260800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1559260800,"objectID":"64538f234b1030a7d33cabe80e59706b","permalink":"https://rowanmcallister.github.io/publication/saved/","publishdate":"2019-05-31T00:00:00Z","relpermalink":"/publication/saved/","section":"publication","summary":"Reinforcement learning (RL) for robotics is challenging due to the difficulty in hand-engineering a dense cost function, which can lead to unintended behavior, and dynamical uncertainty, which makes it hard to enforce constraints during learning. We address these issues with a new model-based reinforcement learning algorithm, safety augmented value estimation from demonstrations (SAVED), which uses supervision that only identifies task completion and a modest set of suboptimal demonstrations to constrain exploration and learn efficiently while handling complex constraints. We derive iterative improvement guarantees for SAVED under known stochastic nonlinear systems. We then compare SAVED with 3 state-of-the-art model-based and model-free RL algorithms on 6 standard simulation benchmarks involving navigation and manipulation and 2 real-world tasks on the da Vinci surgical robot. Results suggest that SAVED outperforms prior methods in terms of success rate, constraint satisfaction, and sample efficiency, making it feasible to safely learn complex maneuvers directly on a real robot in less than an hour. For tasks on the robot, baselines succeed less than 5% of the time while SAVED has a success rate of over 75% in the first 50 training iterations.","tags":null,"title":"Safety Augmented Value Estimation from Demonstrations (SAVED): Safe Deep Model-Based RL for Sparse Cost Robotic Tasks","type":"publication"},{"authors":["Nicholas Rhinehart","Rowan McAllister","Kris Kitani","Sergey Levine"],"categories":null,"content":"","date":1557187200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557187200,"objectID":"4314b09673cf171f2a6de1d76368f903","permalink":"https://rowanmcallister.github.io/publication/precog/","publishdate":"2019-05-07T00:00:00Z","relpermalink":"/publication/precog/","section":"publication","summary":"Forecasting the motion of multiple interacting vehicles. When one is autonmous, conditioning on its goals helps better-predict the motions of other vehicles.","tags":["Autonomous Vehicles"],"title":"PRECOG: PREdiction Conditioned On Goals in Visual Multi-Agent Settings","type":"publication"},{"authors":["Rowan McAllister","Gregory Kahn","Jeff Clune","Sergey Levine"],"categories":null,"content":"","date":1545868800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1545868800,"objectID":"392cad5eb99b10f7e9a745b76f7adc1e","permalink":"https://rowanmcallister.github.io/publication/ood/","publishdate":"2018-12-27T00:00:00Z","relpermalink":"/publication/ood/","section":"publication","summary":"Deep learning provides a powerful tool for machine perception when the observations resemble the training data. However, real-world robotic systems must react intelligently to their observations even in unexpected circumstances. This requires a system to reason about its own uncertainty given unfamiliar, out-of-distribution observations. Approximate Bayesian approaches are commonly used to estimate uncertainty for neural network predictions, but can struggle with out-of-distribution observations. Generative models can in principle detect out-of-distribution observations as those with a low estimated density. However, the mere presence of an out-of-distribution input does not by itself indicate an unsafe situation. In this paper, we present a method for uncertainty-aware robotic perception that combines generative modeling and model uncertainty to cope with uncertainty stemming from out-of-distribution states. Our method estimates an uncertainty measure about the model's prediction, taking into account an explicit (generative) model of the observation distribution to handle out-of-distribution inputs. This is accomplished by probabilistically projecting observations onto the training distribution, such that out-of-distribution inputs map to uncertain in-distribution observations, which in turn produce uncertain task-related predictions, but only if task-relevant parts of the image change. We evaluate our method on an action-conditioned collision prediction task with both simulated and real data, and demonstrate that our method of projecting out-of-distribution observations improves the performance of four standard Bayesian and non-Bayesian neural network approaches, offering more favorable trade-offs between the proportion of time a robot can remain autonomous and the proportion of impending crashes successfully avoided.","tags":["Reinforcement Learning"],"title":"Robustness to Out-of-Distribution Inputs via Task-Aware Generative Uncertainty","type":"publication"},{"authors":["Kurtland Chua","Roberto Calandra","Rowan McAllister","Sergey Levine"],"categories":null,"content":"","date":1541116800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1541116800,"objectID":"9eb0854654ecbd931b95d5384b219ab5","permalink":"https://rowanmcallister.github.io/publication/pets/","publishdate":"2018-11-02T00:00:00Z","relpermalink":"/publication/pets/","section":"publication","summary":"Model-based reinforcement learning (RL) algorithms can attain excellent sample efficiency, but often lag behind the best model-free algorithms in terms of asymptotic performance. This is especially true with high-capacity parametric function approximators, such as deep networks. In this paper, we study how to bridge this gap, by employing uncertainty-aware dynamics models. We propose a new algorithm called probabilistic ensembles with trajectory sampling (PETS) that combines uncertainty-aware deep network dynamics models with sampling-based uncertainty propagation. Our comparison to state-of-the-art model-based and model-free deep RL algorithms shows that our approach matches the asymptotic performance of model-free algorithms on several challenging benchmark tasks, while requiring significantly fewer samples (e.g., 8 and 125 times fewer samples than Soft Actor Critic and Proximal Policy Optimization respectively on the half-cheetah task).","tags":["Reinforcement Learning"],"title":"Deep Reinforcement Learning in a Handful of Trials using Probabilistic Dynamics Models","type":"publication"},{"authors":["Nicholas Rhinehart","Rowan McAllister","Sergey Levine"],"categories":null,"content":"","date":1539561600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1539561600,"objectID":"24431e94f69a8cbd95a0bb1775cb5c7c","permalink":"https://rowanmcallister.github.io/publication/dim/","publishdate":"2018-10-15T00:00:00Z","relpermalink":"/publication/dim/","section":"publication","summary":"Imitation Learning (IL) is an appealing approach to learn desirable autonomous behavior. However, directing IL to achieve arbitrary goals is difficult. In contrast, planning-based algorithms use dynamics models and reward functions to achieve goals. Yet, reward functions that evoke desirable behavior are often difficult to specify. In this paper, we propose \"Imitative Models\" to combine the benefits of IL and goal-directed planning. Imitative Models are probabilistic predictive models of desirable behavior able to plan interpretable expert-like trajectories to achieve specified goals. We derive families of flexible goal objectives, including constrained goal regions, unconstrained goal sets, and energy-based goals. We show that our method can use these objectives to successfully direct behavior. Our method substantially outperforms six IL approaches and a planning-based approach in a dynamic simulated autonomous driving task, and is efficiently learned from expert demonstrations without online data collection.  We also show our approach is robust to poorly-specified goals, such as goals on the wrong side of the road.","tags":["Autonomous Vehicles"],"title":"Deep Imitative Models for Flexible Inference, Planning, and Control","type":"publication"},{"authors":["Rowan McAllister","Carl Rasmussen"],"categories":null,"content":"","date":1512086400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1512086400,"objectID":"af2caa51d9b47076b5554063df582d0c","permalink":"https://rowanmcallister.github.io/publication/fpilco/","publishdate":"2017-12-01T00:00:00Z","relpermalink":"/publication/fpilco/","section":"publication","summary":"We present a data-efficient reinforcement learning method for continuous stateaction systems under significant observation noise. Data-efficient solutions under small noise exist, such as PILCO which learns the cartpole swing-up task in 30s. PILCO evaluates policies by planning state-trajectories using a dynamics model. However, PILCO applies policies to the observed state, therefore planning in observation space. We extend PILCO with filtering to instead plan in belief space, consistent with partially observable Markov decisions process (POMDP) planning. This enables data-efficient learning under significant observation noise, outperforming more naive methods such as post-hoc application of a filter to policies optimised by the original (unfiltered) PILCO algorithm. We test our method on the cartpole swing-up task, which involves nonlinear dynamics and requires nonlinear control.","tags":["Reinforcement Learning","Planning"],"title":"Data-Efficient Reinforcement Learning in Continuous State-Action Gaussian-POMDPs","type":"publication"},{"authors":["Rowan McAllister","Yarin Gal","Alex Kendall","Mark van der Wilk","Amar Shah","Roberto Cipolla","Adrian Weller"],"categories":null,"content":"","date":1503100800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1503100800,"objectID":"5147407aa40769f729df444826aa7125","permalink":"https://rowanmcallister.github.io/publication/avsafety/","publishdate":"2017-08-19T00:00:00Z","relpermalink":"/publication/avsafety/","section":"publication","summary":"Autonomous vehicle (AV) software is typically composed of a pipeline of individual components, linking sensor inputs to motor outputs. Erroneous component outputs propagate downstream, hence safe AV software must consider the ultimate effect of each component's errors. Further, improving safety alone is not sufficient. Passengers must also *feel* safe to trust and use AV systems. To address such concerns, we investigate three under-explored themes for AV research; safety, interpretability, and compliance. *Safety* can be improved by quantifying the uncertainties of component outputs and propagating them forward through the pipeline. *Interpretability* is concerned with explaining what the AV observes and why it makes the decisions it does, building reassurance with the passenger. *Compliance* refers to maintaining some control for the passenger. We discuss open challenges for research within these themes. We highlight the need for concrete evaluation metrics, propose example problems, and highlight possible solutions.","tags":["Autonomous Vehicles"],"title":"Concrete Problems for Autonomous Vehicle Safety: Advantages of Bayesian Deep Learning","type":"publication"},{"authors":["Rowan McAllister"],"categories":null,"content":"","date":1493596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1493596800,"objectID":"6aad632eb6eb4d81dc799d4ff1bf17a6","permalink":"https://rowanmcallister.github.io/publication/phd/","publishdate":"2017-05-01T00:00:00Z","relpermalink":"/publication/phd/","section":"publication","summary":"Applications to learn control of unfamiliar dynamical systems with increasing autonomy are ubiquitous. From robotics, to finance, to industrial processing, autonomous learning helps obviate a heavy reliance on experts for system identification and controller design. Often real world systems are nonlinear, stochastic, and expensive to operate (e.g. slow, energy intensive, prone to wear and tear). Ideally therefore, nonlinear systems can be identified with minimal system interaction. This thesis considers data efficient autonomous learning of control of nonlinear, stochastic systems. Data efficient learning critically requires probabilistic modelling of dynamics. Traditional control approaches use deterministic models, which easily overfit data, especially small datasets. We use probabilistic Bayesian modelling to learn systems from scratch, similar to the PILCO algorithm, which achieved unprecedented data efficiency in learning control of several benchmarks. We extend PILCO in three principle ways. First, we learn control under significant observation noise by simulating a filtered control process using a tractably analytic framework of Gaussian distributions. In addition, we develop the ‘latent variable belief Markov decision process’ when filters must predict under real-time constraints. Second, we improve PILCO’s data efficiency by directing exploration with predictive loss uncertainty and Bayesian optimisation, including a novel approximation to the Gittins index. Third, we take a step towards data efficient learning of high-dimensional control using Bayesian neural networks (BNN). Experimentally we show although filtering mitigates adverse effects of observation noise, much greater performance is achieved when optimising controllers with evaluations faithful to reality; by simulating closed-loop filtered control if executing closed-loop filtered control. Thus, controllers are optimised w.r.t. how they are used, outperforming filters applied to systems optimised by unfiltered simulations. We show directed exploration improves data efficiency. Lastly, we show BNN dynamics models are almost as data efficient as Gaussian process models. Results show data efficient learning of high-dimensional control is possible as BNNs scale to high-dimensional state inputs.","tags":null,"title":"Bayesian Learning for Data-Efficient Control","type":"publication"},{"authors":["Yarin Gal","Rowan McAllister","Carl Rasmussen"],"categories":null,"content":"","date":1466294400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1466294400,"objectID":"c7ee01b13488d6f9297c7dd9623af77d","permalink":"https://rowanmcallister.github.io/publication/dpilco/","publishdate":"2016-06-19T00:00:00Z","relpermalink":"/publication/dpilco/","section":"publication","summary":"Model-based reinforcement learning (RL) allows an agent to discover good policies with a small number of trials by generalising observed transitions. Data efficiency can be further improved with a probabilistic model of the agent’s ignorance about the world, allowing it to choose actions under uncertainty. Bayesian modelling offers tools for this task, with PILCO being a prominent example, achieving state-of-theart data efficiency on low dimensional RL benchmarks. But PILCO relies on Gaussian processes (GPs), which prohibits its applicability to problems that require a larger number of trials to be solved. Further, PILCO does not consider temporal correlation in model uncertainty between successive state transitions, which results in PILCO underestimating state uncertainty at future time steps. In this paper we extend PILCO’s framework to use Bayesian deep dynamics models with approximate variational inference, allowing PILCO to scale linearly with number of trials and observation space dimensionality. Using particle methods we sample dynamics function realisations, and obtain lower cumulative cost than PILCO. We give insights into the modelling assumptions made in PILCO, and show that moment matching is a crucial simplifying assumption made by the model. Our implementation can leverage GPU architectures, offering faster running time than PILCO, and will allow structured observation spaces to be modelled (images or higher dimensional inputs) in the future.","tags":null,"title":"Improving PILCO with Bayesian Neural Network Dynamics Models","type":"publication"},{"authors":["Thierry Peynot","Angela Lui","Rowan McAllister","Robert Fitch","Salah Sukkarieh"],"categories":null,"content":"","date":1410220800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1410220800,"objectID":"30c5e97300aab389a811a9150e0d5bba","permalink":"https://rowanmcallister.github.io/publication/mawson-jfr/","publishdate":"2014-09-09T00:00:00Z","relpermalink":"/publication/mawson-jfr/","section":"publication","summary":"Motion planning for planetary rovers must consider control uncertainty in order to maintain the safety of the platform during navigation. Modeling such control uncertainty is difficult due to the complex interaction between the platform and its environment. In this paper, we propose a motion-planning approach whereby the outcome of control actions is learned from experience and represented statistically using a Gaussian process regression model. This mobility prediction model is trained using sample executions of motion primitives on representative terrain, and it predicts the future outcome of control actions on similar terrain. Using Gaussian process regression allows us to exploit its inherent measure of prediction uncertainty in planning. We integrate mobility prediction into a Markov decision process framework and use dynamic programming to construct a control policy for navigation to a goal region in a terrain map built using an onboard depth sensor. We consider both rigid terrain, consisting of uneven ground, small rocks, and nontraversable rocks, and also deformable terrain. We introduce two methods for training the mobility prediction model from either proprioceptive or exteroceptive observations, and we report results from nearly 300 experimental trials using a planetary rover platform in a Mars-analogue environment. Our results validate the approach and demonstrate the value of planning under uncertainty for safe and reliable navigation.","tags":["Mawson the Robot"],"title":"Learned Stochastic Mobility Prediction for Planning with Control Uncertainty on Unstructured Terrain","type":"publication"},{"authors":["Rowan McAllister","Thierry Peynot","Robert Fitch","Salah Sukkarieh"],"categories":null,"content":"","date":1349568000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1349568000,"objectID":"b3fb5afc4488d633ceb3e93e4c0e7ac3","permalink":"https://rowanmcallister.github.io/publication/mawson-iros/","publishdate":"2012-10-07T00:00:00Z","relpermalink":"/publication/mawson-iros/","section":"publication","summary":"Motion planning for planetary rovers must consider control uncertainty in order to maintain the safety of the platform during navigation. Modelling such control uncertainty is difficult due to the complex interaction between the platform and its environment. In this paper, we propose a motion planning approach whereby the outcome of control actions is learned from experience and represented statistically using a Gaussian process regression model. This model is used to construct a control policy for navigation to a goal region in a terrain map built using an on-board RGB-D camera. The terrain includes flat ground, small rocks, and non-traversable rocks. We report the results of 200 simulated and 35 experimental trials that validate the approach and demonstrate the value of considering control uncertainty in maintaining platform safety.","tags":["Mawson the Robot"],"title":"Motion Planning and Stochastic Control with Experimental Validation on a Planetary Rover","type":"publication"},{"authors":["Rowan McAllister"],"categories":null,"content":"","date":1343779200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1343779200,"objectID":"656dc45078960742f3bf0226a72e2834","permalink":"https://rowanmcallister.github.io/publication/mawson-masters/","publishdate":"2012-08-01T00:00:00Z","relpermalink":"/publication/mawson-masters/","section":"publication","summary":"Planetary rovers are required to safely navigate across unstructured and hazardous terrain with increasing levels of autonomy. Autonomy is necessary to react to impending danger because remote control has been proved challenging and dangerous for planetary rovers due to the large communication delays. Safety is especially a concern in space applications where a robot is unaccompanied throughout its entire mission. Unstructured terrain poses several types of hazards to a robot such as getting stuck, toppling or scraping against rocks. In a dense collection of localised hazards, platform safety is very sensitive to deviations from an intended path. To maintain the safety of the platform during navigation, planetary rovers must consider control uncertainty during motion planning. Thus, not only does the system need to make predictions of action outcomes, it also needs to estimate the accuracy of these predictions. The aim of this research is to provide planetary rovers with the ability to plan motions to goal regions that optimise the safety of the platform by including information about the accuracy of its controls. Modelling such control uncertainty is diffcult due to the complex interaction between the platform and its environment. In this thesis, we propose an approach to learn the outcome of control actions from experience, represented statistically using a Gaussian Process regression model. This model is incorporated explicitly in the planning process using dynamic programming to construct a control policy for navigation to a goal region. Motion planning strategies are considered that take into account different types of uncertainties, including uncertainty in distance, heading and yaw of the platform, across various motion primitives. The approach is implemented on a holonomic rover with six wheels and a Rocker-bogie frame and tested on a Mars analogue terrain that includes flat ground, small rocks, and non-traversable rocks. Planning is computed over a terrain map built using an on-board RGB-D camera. We report the results of 200 simulated and 95 experimental trials that validate the approach. These results demonstrate that explicitly incorporating knowledge of control uncertainty into the motion planning process increases platform safety by decreasing the likelihood of the rover getting stuck and reducing the cost accumulated over the executed path. Accounting for heading uncertainty resulted in the most significant increase in platform safety.","tags":["Mawson the Robot"],"title":"Motion Planning and Stochastic Control with Experimental Validation on a Planetary Rover","type":"publication"},{"authors":["Rowan McAllister"],"categories":null,"content":"","date":1257379200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1257379200,"objectID":"e9c4264ea1e976ea01194cfffc8c9354","permalink":"https://rowanmcallister.github.io/publication/undergrad/","publishdate":"2009-11-05T00:00:00Z","relpermalink":"/publication/undergrad/","section":"publication","summary":"Self-Reconfiguring Robots (SRR) are composed of many modules that have the ability to autonomously attach and detach, enabling adaptation to a variety of tasks in unknown surroundings. In order to change shape into a particular form, an SRR must plan a sequence of module movements. This reconfiguration problem is challenging because of the many mechanical degrees of freedom and the resultant large number of possible SRR configurations which contribute to a vast and high-dimensional search space. To support the operation of an SRR in a practical environment, reconfiguration planners must satisfy a number of properties including decentralized computation, parallel motion of modules, real-time execution and planning in the native kinematic space of the module mechanism. The ultimate solution would be a general planner that solves reconfigurations of arbitrary module designs in this way. This thesis has taken a step in this direction of generality by developing a reconfiguration planner of the 3R module that is easily instantiable to other module types. The planner is scalable and decentralized, and considers the native kinematics of a module. It demonstrates the ability to coordinate the parallel motion of modules and executes in real-time. The thesis presents both centralized and decentralized implementations of the algorithm along with performance evaluation for several reconfiguration examples, as well as an analysis of achievable SRR reconfigurations.","tags":["Modular Robots"],"title":"Autonomous Reconfiguration Planning in Modular Robots","type":"publication"}]